{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/eldanc/mlbootcamp2024/blob/main/lab_4_1_gnn.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n","\n","# UofT DSI-CARTE ML Bootcamp\n","#### June 13th, 2024\n","#### Graph Neural Networks - Lab 1, Day 4\n","#### Teaching team: Eldan Cohen, Nakul Upadhya, Hriday Chedda, Alex Olson\n","##### Lab author: Pytorch Geometric Team (Modified by Nakul Upadhya)\n","\n","Recently, deep learning on graphs has emerged to one of the hottest research fields in the deep learning community.\n","Here, **Graph Neural Networks (GNNs)** aim to generalize classical deep learning concepts to irregular structured data (in contrast to images or texts) and to enable neural networks to reason about objects and their relations.\n","\n","This tutorial will introduce you to some fundamental concepts regarding deep learning on graphs via Graph Neural Networks based on the **[PyTorch Geometric (PyG) library](https://github.com/rusty1s/pytorch_geometric)**.\n","PyTorch Geometric is an extension library to the popular deep learning framework [PyTorch](https://pytorch.org/), and consists of various methods and utilities to ease the implementation of Graph Neural Networks.\n","\n","\n","Lets first start by installing and importing relevant packages:"],"metadata":{"id":"7bXAzL0sXvWd"}},{"cell_type":"code","metadata":{"id":"zF5bw3m9UrMy"},"source":["# Install required packages.\n","import os\n","import torch\n","\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qoW2Z7P70LNQ"},"source":["## Graph Neural Networks\n","GNNs operate through a **neural message passing scheme**, where node features $\\mathbf{x}_v^{(\\ell)}$ of all nodes $v \\in \\mathcal{V}$ in a graph $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})$ are iteratively updated by aggregating  information from their neighbors $\\mathcal{N}(v)$:\n","\n","$$\n","\\mathbf{x}_v^{(\\ell + 1)} = f^{(\\ell + 1)}_{\\theta} \\left( \\mathbf{x}_v^{(\\ell)}, \\left\\{ \\mathbf{x}_w^{(\\ell)} : w \\in \\mathcal{N}(v) \\right\\} \\right)\n","$$\n","\n","\n","\n","To demonstrate, we make use of the `Cora` dataset, which is a **citation network** where nodes represent documents.\n","Each node is described by a 1433-dimensional bag-of-words feature vector.\n","Two documents are connected if there exists a citation link between them.\n","The task is to infer the category of each document (7 in total).\n","\n","This dataset was first introduced by [Yang et al. (2016)](https://arxiv.org/abs/1603.08861) as one of the datasets of the `Planetoid` benchmark suite.\n","We again can make use [PyTorch Geometric](https://github.com/rusty1s/pytorch_geometric) for an easy access to this dataset via [`torch_geometric.datasets.Planetoid`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.Planetoid):"]},{"cell_type":"code","metadata":{"id":"H_VTFHd0uFz6"},"source":["from torch_geometric.datasets import Planetoid\n","from torch_geometric.transforms import NormalizeFeatures\n","\n","dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n","data = dataset[0]  # Planetoid contains a lot of graphs. We just want the first one, which is the Cora dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can get information about the dataset by printing `data`"],"metadata":{"id":"HVwFx2rLDLf5"}},{"cell_type":"code","source":["print(data)"],"metadata":{"id":"9-QbOLpxq54r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7cjjyFVnpKB0"},"source":["The `data` object contains various attributes:\n","1. `x`: This is the feature matrix where each row is a node in the graph, and each column is a feature. The features here are the presence of words in the academic paper.\n","2. `y`: This is the label vector\n","3. `edge_index`: PyG stores the structure of the graph by saving the *edge indexes*. For each edge, `edge_index` holds a tuple of two node indices, where the first value describes the node index of the source node and the second value describes the node index of the destination node of an edge.\n","4. `train_mask`/`val_mask`/`test_mask`: Since the Cora dataset is often used as a benchmark, the developers have marked what nodes should be in the training/validation/test datsets.\n","\n","**Your Turn**\n","* How many nodes are there in this graph?\n","* How many edges are there?\n","\n","\n","PyG stores the graph in what is known as the **COO format (coordinate format)** commonly used for representing sparse matrices.\n","Instead of holding the adjacency information in a dense representation $\\mathbf{A} \\in \\{ 0, 1 \\}^{|\\mathcal{V}| \\times |\\mathcal{V}|}$, PyG represents graphs sparsely, which refers to only holding the coordinates/values for which entries in $\\mathbf{A}$ are non-zero.\n","\n","Importantly, *PyG does not distinguish between directed and undirected graphs*, and treats undirected graphs as a special case of directed graphs in which reverse edges exist for every entry in `edge_index`.\n","\n","\n","\n","By printing `edge_index`, we can see this representation"]},{"cell_type":"code","metadata":{"id":"ci-LpZWhRJoI"},"source":["from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","edge_index = data.edge_index\n","print(edge_index.t()) # .t() transposes the tensor so each edge is a row."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Treating the graph as Tabular Data\n","\n","In theory, we should be able to infer the category of a document solely based on its content, *i.e.* its bag-of-words feature representation, without taking any relational information into account.\n","\n","Let's verify that by constructing a simple MLP that solely operates on input node features (using shared weights across all nodes):"],"metadata":{"id":"AWzgu4-jlrSJ"}},{"cell_type":"code","source":["import torch\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","\n","\n","class MLP(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super().__init__()\n","        self.lin1 = Linear(dataset.num_features, hidden_channels)\n","        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n","\n","    def forward(self, x):\n","        x = self.lin1(x)\n","        x = F.relu(x)\n","        x = self.lin2(x)\n","        return x\n","\n","model = MLP(hidden_channels=16)"],"metadata":{"id":"zEQsCS-mlr2o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Our MLP is defined by two linear layers and enhanced by [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU) non-linearity and [dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html?highlight=dropout#torch.nn.Dropout).\n","Here, we first reduce the 1433-dimensional feature vector to a low-dimensional embedding (`hidden_channels=16`), while the second linear layer acts as a classifier that should map each low-dimensional node embedding to one of the 7 classes.\n","\n","Now let us define our data loaders\n","\n"],"metadata":{"id":"Q2MKvB-_luv1"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","train_tabular_features = data.x[data.train_mask]\n","test_tabular_features = data.x[data.test_mask]\n","\n","train_tabular_label = data.y[data.train_mask]\n","test_tabular_label = data.y[data.test_mask]\n","\n","\n","train_loader = DataLoader(TensorDataset(train_tabular_features, train_tabular_label), batch_size=32, shuffle=True)\n","test_loader = DataLoader(TensorDataset(test_tabular_features, test_tabular_label), batch_size=32, shuffle=False)\n"],"metadata":{"id":"lXmkZJOFFWwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's train our simple MLP by making use of the **cross entropy loss** and **Adam optimizer**. We will also define a **`test` function** to evaluate how well our final model performs on the test node set (which labels have not been observed during training)."],"metadata":{"id":"RIbnREwWFV0u"}},{"cell_type":"code","source":["from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","model = MLP(hidden_channels=16)\n","criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n","\n","\n","epochs = 200\n","iterations = 0\n","for epoch in range(epochs):\n","  for batch_idx, (x, y) in enumerate(train_loader):\n","    model.train()\n","    model.zero_grad()\n","    out = model(x)\n","    loss = criterion(out,y)\n","    loss.backward()\n","    optimizer.step()\n","  if epoch % 25 == 0:\n","    with torch.no_grad():\n","      model.eval()\n","      correct = 0\n","      for x, y in test_loader:\n","        out = model(x)\n","        pred = out.argmax(dim=1)\n","        correct += int((pred == y).sum())\n","\n","      test_acc = correct / len(test_loader.dataset)\n","      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')"],"metadata":{"id":"kxszTQISlu2X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Your Turn:**\n","\n","The model performed badly, with only a 60% accuracy. What are potential reasons for this poor performance given what you know about the type of data we are working with?"],"metadata":{"id":"4RuS4ftewqLL"}},{"cell_type":"markdown","metadata":{"id":"kPbYXBn1yYIJ"},"source":["## Implementing Graph Neural Networks\n","\n","After learning about PyG's data handling, it's time to implement our first Graph Neural Network!\n","\n","For this, we will use on of the most simple GNN operators, the **GCN layer** ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)), which is defined as\n","\n","$$\n","\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n","$$\n","\n","where $\\mathbf{W}^{(\\ell + 1)}$ denotes a trainable weight matrix of shape `[num_output_features, num_input_features]` and $c_{w,v}$ refers to a fixed normalization coefficient for each edge. We can easily convert our MLP to a GNN by swapping the `torch.nn.Linear` layers with PyG's GNN operators.\n","\n","\n","PyG implements this layer via [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv), which can be executed by passing in **both** the node feature representation `x` and the COO graph connectivity representation `edge_index`.\n","\n","With this, we are ready to create our first Graph Neural Network by defining our network architecture in a `torch.nn.Module` class:"]},{"cell_type":"code","metadata":{"id":"AkQAVluLuxT_"},"source":["import torch\n","from torch.nn import Linear\n","from torch_geometric.nn import GCNConv\n","class GCN(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super().__init__()\n","        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n","        self.lin = Linear(hidden_channels, dataset.num_classes)\n","    def forward(self, x, edge_index):\n","        h = self.conv1(x, edge_index)\n","        h = h.relu()\n","        h = self.conv2(h, edge_index)\n","        h = h.relu() # h is the embedding before the linear layer\n","        out = self.lin(h)\n","        return out, h\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjsb3Fst2P8k"},"source":["Here, we first initialize all of our building blocks in `__init__` and define the computation flow of our network in `forward`.\n","We first define and stack **two graph convolution layers**, which corresponds to aggregating 2-hop neighborhood information around each node (**all nodes up to 2 \"hops\" away**).\n","\n","After that, we apply a single linear transformation ([`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear)) that acts as a classifier to map our nodes to 1 out of the 7 classes.\n","\n","We return both the output of the final classifier as well as the final node embeddings produced by our GNN.\n"]},{"cell_type":"markdown","metadata":{"id":"1-W5Kfhu5I-P"},"source":["\n","\n","### Training on the Graph\n","\n","\n","Training our model is very similar to any other PyTorch model.\n","In addition to defining our network architecture, we define a loss critertion (here, [`CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)) and initialize a stochastic gradient optimizer (here, [`Adam`](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam)).\n","\n","After that, we perform multiple rounds of optimization, where each round consists of a forward and backward pass to compute the gradients of our model parameters w.r.t. to the loss derived from the forward pass.\n"]},{"cell_type":"markdown","source":["#### Dataloaders\n","Compared to tabular data, graph data requires a different type of dataloader: the `NeighborLoader` which loads in nodes AND the neighbors of that node.\n","\n","If we simply use the normal dataloader for a graph neural network, we may lose information about the graph by accidentally dropping nodes.\n","\n","Lets create our training and testing neighbor loaders now.\n"],"metadata":{"id":"5xYSA0Iak8qQ"}},{"cell_type":"code","source":["from torch_geometric.loader import NeighborLoader\n","\n","train_loader = NeighborLoader(\n","    data,\n","    # Sample 30 neighbors for each node for 2 iterations\n","    num_neighbors=[30] * 2,\n","    # Use a batch size of 128 for sampling training nodes\n","    batch_size=128,\n","    input_nodes=data.train_mask,\n",")\n","test_loader = NeighborLoader(\n","    data,\n","    # Sample 30 neighbors for each node for 2 iterations\n","    num_neighbors=[30] * 2,\n","    # Use a batch size of 128 for sampling training nodes\n","    batch_size=128,\n","    input_nodes=data.train_mask,\n",")"],"metadata":{"id":"dz12NBe_k8GQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Your Turn**\n","\n","In the cell below,we print out one batch of data from the train loader.\n","* How many training points are there?\n","* If there are more training points than expected in the batch, why do you think that is?\n","\n","\n","\n"],"metadata":{"id":"v56bsUBhs17e"}},{"cell_type":"code","source":["print(next(iter(train_loader)))"],"metadata":{"id":"Nv8SvrU0s-Jx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","While we compute node embeddings for all of our nodes, we **only make use of the training nodes for computing the loss**.\n","Here, this is implemented by filtering the output of the classifier `out` and ground-truth labels `data.y` to only contain the nodes in the `train_mask`.\n","\n","Now, lets train!"],"metadata":{"id":"aKpksfV_lQ4w"}},{"cell_type":"code","metadata":{"id":"etxOsz8QIbMO"},"source":["import time\n","from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 430})'''))\n","\n","model = GCN(hidden_channels=16)\n","criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.\n","\n","epochs = 200\n","iterations = 0\n","for epoch in range(epochs):\n","  for batch_idx, batch_data in enumerate(train_loader):\n","    model.train()\n","    model.zero_grad()\n","    # get relevant nodes and targets\n","    x = batch_data.x\n","    y = batch_data.y\n","    edge_index = batch_data.edge_index\n","    train_mask = batch_data.train_mask # retrieve train mask\n","\n","    out,_ = model(x, edge_index)\n","\n","    ## We filter the points and remove any points that are not part of the\n","    ## training set.\n","    relevant_output = out[train_mask]\n","    relevant_y = y[train_mask]\n","\n","    loss = criterion(relevant_output, relevant_y)\n","    loss.backward()\n","    optimizer.step()\n","\n","  if epoch % 25 == 0:\n","    with torch.no_grad():\n","      model.eval()\n","      correct = 0\n","      total = 0\n","      for _, test_batch in enumerate(test_loader):\n","        x_test = test_batch.x\n","        y_test = test_batch.y\n","        test_mask = test_batch.test_mask\n","        out, _ = model(x_test, test_batch.edge_index)\n","        pred = out.argmax(dim=1)\n","        correct += int((pred == y_test).sum())\n","        total += len(y_test)\n","      test_acc = correct / total\n","      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As one can see, our GCN model manages to dramatically increase the accuracy of the classification task!\n"],"metadata":{"id":"8vLIlndA5rML"}},{"cell_type":"markdown","source":["### Visualizing Node Embeddings\n","\n","Along with simply training a classifer, once can use the embeddings generated by the GCN for other downstream tasks. Additionally, we can visualize the embeddings to see how well each class is seperated:"],"metadata":{"id":"gM9Ht2FO5WR5"}},{"cell_type":"code","source":["from sklearn.manifold import TSNE\n","\n","_,embedding = model(data.x, data.edge_index)\n","tsne = TSNE(n_components=2)\n","embedding = tsne.fit_transform(embedding.detach().numpy())"],"metadata":{"id":"PPKInZHO44Vd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.scatter(embedding[:, 0], embedding[:, 1], s=50, c=data.y,\n","           cmap=plt.cm.get_cmap('viridis', 7))\n","plt.colorbar()\n","plt.show()"],"metadata":{"id":"J63kP1W0rEkN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As we can see, the network has learned a representation in which the classes are relatively well seperated."],"metadata":{"id":"nwXYVkEh5s_1"}}]}