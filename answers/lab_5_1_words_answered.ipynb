{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# UofT FASE ML Bootcamp\n",
        "#### Friday June 14, 2024\n",
        "####  Word Embeddings - Properties, Meaning and Training - Lab 1, Day 5\n",
        "#### Teaching team: Eldan Cohen, Alex Olson, Nakul Upadhya, Hriday Chheda\n",
        "##### Based on CARTE-DSI ML Bootcamp 2023 notebook by Prof. Jonathan Rose\n",
        "\n",
        "This lab engages you in the properties, meaning, viewing and training of word embeddings (also called word vectors). The specific learning objectives in this assignment are:\n",
        "\n",
        "1.   To learn word embedding properties, and use them in simple ways.\n",
        "2.   (optional) To translate vectors into understandable categories of meaning\n",
        "3.   To understand how embeddings are created, using the Skip Gram method.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qDdF-DpXWg1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Experimenting and Understanding Word Embedding/Vectors\n",
        "# Using the GloVe Embeddings\n",
        "\n",
        "\n",
        "Word embeddings (also known as word vectors) are a way to encode the meaning of words into a set of numbers.\n",
        "\n",
        "These embeddings are created by training a neural network model using many examples of the use of language.  These examples could be the whole of Wikipedia or a large collection of news articles.\n",
        "\n",
        "To start, we will explore a set of word embeddings that someone else took the time and computational power to create. One of the most commonly-used pre-trained word embeddings are the **GloVe embeddings**."
      ],
      "metadata": {
        "id": "UMKnFM6Wkl46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe Embeddings\n",
        "\n",
        "You can read about the GloVe embeddings here: https://nlp.stanford.edu/projects/glove/, and read the original paper describing how they work here: https://nlp.stanford.edu/pubs/glove.pdf.\n",
        "\n",
        "There are several variations of GloVe embeddings. They differ in the text used to train the embedding, and the *size* of the embeddings.\n",
        "\n",
        "Throughout this lab we'll use a package called `torchtext`, that is part of PyTorch.\n",
        "\n",
        "We'll begin by loading a set of GloVe embeddings. The first time you run the code below, it will cause the download of a large file (862MB) containing the embeddings."
      ],
      "metadata": {
        "id": "rNg2XmmFlfuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import torch\n",
        "import torchtext\n",
        "import pandas as pd\n",
        "torchtext.disable_torchtext_deprecation_warning()\n",
        "from torchtext.vocab import GloVe"
      ],
      "metadata": {
        "id": "PjRMuu2Fnb9H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ypuiFEIYWfkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4678740b-867d-4312-f9a9-3743a90f8cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:23<00:00, 16729.41it/s]\n"
          ]
        }
      ],
      "source": [
        "# The first time you run this will download a ~862MB file\n",
        "glove = GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "              dim=50)  # embedding size = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the loaded glove embeddings to look up the embeddings of individual words.\n",
        "For example, let's look at what the embedding of the word \"apple\" looks like:"
      ],
      "metadata": {
        "id": "NiKD_dpmtuWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove['apple']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4i4ocTQmIYQ",
        "outputId": "82c6c62e-b1d8-4a37-bfd5-13500ce2579c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5204, -0.8314,  0.4996,  1.2893,  0.1151,  0.0575, -1.3753, -0.9731,\n",
              "         0.1835,  0.4767, -0.1511,  0.3553,  0.2591, -0.7786,  0.5218,  0.4769,\n",
              "        -1.4251,  0.8580,  0.5982, -1.0903,  0.3357, -0.6089,  0.4174,  0.2157,\n",
              "        -0.0742, -0.5822, -0.4502,  0.1725,  0.1645, -0.3841,  2.3283, -0.6668,\n",
              "        -0.5818,  0.7439,  0.0950, -0.4787, -0.8459,  0.3870,  0.2369, -1.5523,\n",
              "         0.6480, -0.1652, -1.4719, -0.1622,  0.7986,  0.9739,  0.4003, -0.2191,\n",
              "        -0.3094,  0.2658])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the output above, the embedding of a given word is a torch tensor with dimension `(50,)`. We don't know what the meaning of each number is, but we do know that there are properties of the embeddings that can be observed. For example, `distances between embeddings` are meaningful.\n",
        "\n",
        "## Measuring Distance\n",
        "\n",
        "Let's consider one specific metric of distance between two embedding vectors called the **Euclidean distance**. The Euclidean distance of two vectors $x = [x_1, x_2, ... x_n]$ and\n",
        "$y = [y_1, y_2, ... y_n]$ is just the 2-norm of their difference $x - y$. We can compute\n",
        "the Euclidean distance between $x$ and $y$: $\\sqrt{\\sum_i (x_i - y_i)^2}$\n",
        "\n",
        "The PyTorch function `torch.norm` computes the 2-norm of a vector for us, so we\n",
        "can compute the Euclidean distance between two vectors like this:"
      ],
      "metadata": {
        "id": "GB-dyAZjvdKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = glove['cat']\n",
        "y = glove['dog']\n",
        "torch.norm(y - x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvhg6S-vNjj",
        "outputId": "d551830c-66a2-45df-b970-f88674401f95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.8846)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = glove['apple']\n",
        "b = glove['orange']\n",
        "torch.norm(b - a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_897mUSTwAwK",
        "outputId": "bded2c1d-71ac-4cfc-8e89-9677d9f45188"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.9094)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(glove['good'] - glove['bad'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z-zVh8CwMtd",
        "outputId": "4aa1dfb2-382e-4a36-cbfe-73f4258107de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3189)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(glove['good'] - glove['water'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgfIIcTxwO99",
        "outputId": "036340d6-44f4-4b5d-ca07-d804c1304324"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.3390)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(glove['good'] - glove['well'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZAQ64sNwRfK",
        "outputId": "89b35c1e-a1bb-4485-ad77-37dcb9e1c33e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.7703)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(glove['good'] - glove['perfect'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEdfGmh7wmN2",
        "outputId": "96a88eaf-e569-4469-851e-cf65b00d05e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8834)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine Similarity\n",
        "\n",
        "An alternative and more commonly-used measure of distance is the **Cosine Similarity**. The cosine similarity measures the *angle* between two vectors, and has the property that it only considers the *direction* of the vectors, not their the magnitudes. It is computed as follows for two vectors A and B:\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1hSaQRBjH828lx1xozJCA4F0ZhiX2S0Xt)"
      ],
      "metadata": {
        "id": "FwCYQe_XxLik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#consider two vectors x and y\n",
        "#unsqueeze is used because cosine similarity wants at least 2-D inputs\n",
        "x = torch.tensor([1., 1., 1.]).unsqueeze(0)\n",
        "y = torch.tensor([2., 2., 2.]).unsqueeze(0)\n",
        "\n",
        "# Calculate the cosine similarity between x and y\n",
        "# Expect the cosine similarity to be 1.0 since x and y are in the same direction\n",
        "torch.cosine_similarity(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd8iVpD4wp28",
        "outputId": "1b3d0da1-20c2-476b-d337-7cf3aa4e47dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cosine similarity is actually a *similarity* measure rather than a *distance* measure, and gives a result between -1 and 1. Thus, the larger the similarity, (closer to 1) the \"closer in meaning\" the word embeddings are to each other."
      ],
      "metadata": {
        "id": "-kAON3H92whE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.tensor([-1., -1., -1.]).unsqueeze(0)\n",
        "\n",
        "# Calculate the cosine similarity between x and z\n",
        "# Expect the cosine similarity to be -1.0 since x and z point in the opposite \"direction\"\n",
        "torch.cosine_similarity(x, z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNotYDzszo4h",
        "outputId": "c72f4c68-36e3-4a78-83cb-acb767f91c74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = glove['cat']\n",
        "y = glove['dog']\n",
        "torch.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT_gUzm34S2V",
        "outputId": "26045439-457d-42c8-8ea3-244ad434dbd8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9218])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = glove['apple']\n",
        "b = glove['banana']\n",
        "torch.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BsgHFVF4W9_",
        "outputId": "7b95f249-1987-4e2c-e9af-81fa5fcdb562"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5608])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['bad'].unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF8vDFMg4adK",
        "outputId": "97dcb31a-a0cd-41b9-e8db-6b3dae69f860"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7965])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['water'].unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCTpK0304mXF",
        "outputId": "b30dc613-1bce-4b5b-ced8-8196839a0895"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5540])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['well'].unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on933r1J4emF",
        "outputId": "942ac158-dc65-4c5b-c1dd-585ba76cea66"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8511])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['perfect'].unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIk0UjYx4kwR",
        "outputId": "f0b52af7-8f30-4093-c82a-8f5c64e9e878"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8376])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['watermelon'].unsqueeze(0),\n",
        "                        glove['aeroplane'].unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrAwetzf4v77",
        "outputId": "94095964-b1da-4578-9fc0-bc54fc89f20b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1102])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: torch.cosine_similarity requires two dimensions to work, which is created with the unsqueeze option, illustrated in more detail below"
      ],
      "metadata": {
        "id": "GoYuQxTa5TwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = glove['good']\n",
        "print(x.shape) # [50]\n",
        "y = x.unsqueeze(0) # [1, 50]\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4OFVPiU5TRv",
        "outputId": "46ac113f-2cf4-4f4d-8826-e3e005a6c08d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50])\n",
            "torch.Size([1, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Similarity\n",
        "\n",
        "Now that we have notions of distance and similarity in our embedding space, we can talk about words that are \"close\" to each other in the embedding space. For now, let's use Euclidean distances to look at how close various words are to the word \"cat\"."
      ],
      "metadata": {
        "id": "YR-6jQto5b8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'cat'\n",
        "other = ['pet', 'dog', 'bike', 'kitten', 'puppy', 'kite', 'computer', 'neuron']\n",
        "for w in other:\n",
        "    dist = torch.norm(glove[word] - glove[w]) # euclidean distance\n",
        "    print(w, \"\\t%5.2f\" % float(dist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wg_H1Bk48ZC",
        "outputId": "f9eea956-7b91-4c60-f6f3-9e7499d7f2c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pet \t 3.04\n",
            "dog \t 1.88\n",
            "bike \t 5.05\n",
            "kitten \t 3.51\n",
            "puppy \t 3.06\n",
            "kite \t 4.21\n",
            "computer \t 6.03\n",
            "neuron \t 6.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do the same thing with cosine similarity:"
      ],
      "metadata": {
        "id": "NT2_dyt-6LZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'cat'\n",
        "other = ['pet', 'dog', 'bike', 'kitten', 'puppy', 'kite', 'computer', 'neuron']\n",
        "for w in other:\n",
        "    dist = torch.cosine_similarity(glove[word].unsqueeze(0),glove[w].unsqueeze(0)) # cosine distance\n",
        "    print(w, \"\\t%5.2f\" % float(dist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwBTNAz96AFg",
        "outputId": "d7943ff1-d005-4cdc-8fa4-33cf50dde6ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pet \t 0.78\n",
            "dog \t 0.92\n",
            "bike \t 0.44\n",
            "kitten \t 0.64\n",
            "puppy \t 0.76\n",
            "kite \t 0.49\n",
            "computer \t 0.35\n",
            "neuron \t 0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can look through the entire **vocabulary** for words that are closest to a point in the embedding space -- for example, we can look for words that are closest to another word such as \"cat\"."
      ],
      "metadata": {
        "id": "QumucClS6b8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_closest_words(vec, n=5):\n",
        "    dists = torch.norm(glove.vectors - vec, dim=1)     # compute distances to all words\n",
        "    lst = sorted(enumerate(dists.numpy()), key=lambda x: x[1]) # sort by distance\n",
        "    closest_words = []\n",
        "    for idx, difference in lst[1:n+1]:                         # take the top n\n",
        "        print(glove.itos[idx], \"\\t%5.2f\" % difference)\n",
        "        closest_words.append(glove.itos[idx])\n",
        "    return closest_words\n",
        "\n",
        "closest_words_to_cat = print_closest_words(glove[\"cat\"], n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MxGErGA6O9h",
        "outputId": "3a3cbf4e-7d47-4d22-e2d8-bc4afc2d4579"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog \t 1.88\n",
            "rabbit \t 2.46\n",
            "monkey \t 2.81\n",
            "cats \t 2.90\n",
            "rat \t 2.95\n",
            "beast \t 2.99\n",
            "monster \t 3.00\n",
            "pet \t 3.04\n",
            "snake \t 3.06\n",
            "puppy \t 3.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest_words_to_dog = print_closest_words(glove['dog'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6JQA84I6j4S",
        "outputId": "96db5802-6968-460c-8a96-89edde6d26f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat \t 1.88\n",
            "dogs \t 2.65\n",
            "puppy \t 3.15\n",
            "rabbit \t 3.18\n",
            "pet \t 3.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest_words_to_nurse = print_closest_words(glove['nurse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmQicawa8IL9",
        "outputId": "4c27fea2-c3c9-43fc-a882-acb37dcf1f34"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doctor \t 3.13\n",
            "dentist \t 3.13\n",
            "nurses \t 3.27\n",
            "pediatrician \t 3.32\n",
            "counselor \t 3.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest_words_to_computer = print_closest_words(glove['computer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD3G-pMF8WjO",
        "outputId": "f8f1f39c-11c1-4fc8-ce2b-367d61b2624b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computers \t 2.44\n",
            "software \t 2.93\n",
            "technology \t 3.19\n",
            "electronic \t 3.51\n",
            "computing \t 3.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#You can also try printing closest words to any other words of your choice here:\n",
        "\n"
      ],
      "metadata": {
        "id": "ThHIes6D8dJG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could also look at which words are closest to the midpoints of two words:"
      ],
      "metadata": {
        "id": "yuDTCwCI90qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "closest_to_mid_1 = print_closest_words((glove['happy'] + glove['sad']) / 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGusXTUB91R3",
        "outputId": "f8f175e4-03b7-4b0b-c157-19e3f55583c0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy \t 1.92\n",
            "feels \t 2.36\n",
            "sorry \t 2.50\n",
            "hardly \t 2.53\n",
            "imagine \t 2.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest_to_mid_2 = print_closest_words((glove['lake'] + glove['building']) / 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV-ISeLA96js",
        "outputId": "5a1f78db-a8a6-4a62-b615-cd8087807093"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "surrounding \t 3.07\n",
            "nearby \t 3.11\n",
            "bridge \t 3.16\n",
            "along \t 3.16\n",
            "shore \t 3.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest_to_mid_3 = print_closest_words((glove['bravo'] + glove['michael']) / 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wo_X6Bp-cC4",
        "outputId": "74f1310e-cb9e-45b3-f5ed-b02a184ca12a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "farrell \t 2.80\n",
            "anderson \t 2.85\n",
            "jacobs \t 2.85\n",
            "boyle \t 2.86\n",
            "slater \t 2.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1\n",
        "1.1.1 Write a new function, similar to print_closest_words called print_closest_cosine_words that prints out the N-most (where N is an input parameter) similar words using cosine similarity rather than euclidean distance.\n",
        "\n",
        "The documentation for the [sorted](https://python-reference.readthedocs.io/en/latest/docs/functions/sorted.html) method in python might help\n",
        "\n"
      ],
      "metadata": {
        "id": "qerwkoJVAL7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_closest_cosine_words(vec, n=5):\n",
        "  # TODO\n",
        "  sims = torch.cosine_similarity(glove.vectors, vec, dim=1)  # compute similarities to all words\n",
        "  lst =  sorted(enumerate(sims.numpy()), key=lambda x: x[1], reverse=True) # sort by similarity (descending order, remember higher similarity score, closer the word)\n",
        "  closest_words = []\n",
        "  # take the top n\n",
        "  for idx, similarity in lst[1:n+1]:\n",
        "    print(glove.itos[idx], \"\\t%5.2f\" % similarity)\n",
        "    closest_words.append(glove.itos[idx])\n",
        "  return closest_words"
      ],
      "metadata": {
        "id": "Q2KJmHdgAJkZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1.2 Create a table that compares the 10-most cosine-similar words to the word 'dog', in order, alongside to the 10 closest"
      ],
      "metadata": {
        "id": "BVnUuCl1BL_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "closest_euclidean_words = print_closest_words(glove['dog'], n=10)\n",
        "print(\"\\n\")\n",
        "closest_cosine_words = print_closest_cosine_words(glove['dog'], n=10)\n",
        "print(\"\\n\")\n",
        "table = pd.DataFrame()\n",
        "table[\"Euclidean\"] = closest_euclidean_words\n",
        "table[\"Cosine\"] = closest_cosine_words\n",
        "print(table)"
      ],
      "metadata": {
        "id": "2h4QDcObCtrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27202dc5-04bf-4d81-99ca-5a7433c634b7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat \t 1.88\n",
            "dogs \t 2.65\n",
            "puppy \t 3.15\n",
            "rabbit \t 3.18\n",
            "pet \t 3.23\n",
            "horse \t 3.25\n",
            "pig \t 3.39\n",
            "pack \t 3.43\n",
            "cats \t 3.44\n",
            "bite \t 3.46\n",
            "\n",
            "\n",
            "cat \t 0.92\n",
            "dogs \t 0.85\n",
            "horse \t 0.79\n",
            "puppy \t 0.78\n",
            "pet \t 0.77\n",
            "rabbit \t 0.77\n",
            "pig \t 0.75\n",
            "snake \t 0.74\n",
            "baby \t 0.74\n",
            "bite \t 0.74\n",
            "\n",
            "\n",
            "  Euclidean  Cosine\n",
            "0       cat     cat\n",
            "1      dogs    dogs\n",
            "2     puppy   horse\n",
            "3    rabbit   puppy\n",
            "4       pet     pet\n",
            "5     horse  rabbit\n",
            "6       pig     pig\n",
            "7      pack   snake\n",
            "8      cats    baby\n",
            "9      bite    bite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the same table for word \"computer\"\n",
        "closest_euclidean_words = print_closest_words(glove['computer'], n=10)\n",
        "print(\"\\n\")\n",
        "closest_cosine_words = print_closest_cosine_words(glove['computer'], n=10)\n",
        "print(\"\\n\")\n",
        "table = pd.DataFrame()\n",
        "table[\"Euclidean\"] = closest_euclidean_words\n",
        "table[\"Cosine\"] = closest_cosine_words\n",
        "print(table)"
      ],
      "metadata": {
        "id": "ihkV86ACKU7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58d752d-7af1-4c3c-c5be-183f0f6ed067"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computers \t 2.44\n",
            "software \t 2.93\n",
            "technology \t 3.19\n",
            "electronic \t 3.51\n",
            "computing \t 3.60\n",
            "devices \t 3.67\n",
            "hardware \t 3.68\n",
            "internet \t 3.69\n",
            "applications \t 3.69\n",
            "digital \t 3.70\n",
            "\n",
            "\n",
            "computers \t 0.92\n",
            "software \t 0.88\n",
            "technology \t 0.85\n",
            "electronic \t 0.81\n",
            "internet \t 0.81\n",
            "computing \t 0.80\n",
            "devices \t 0.80\n",
            "digital \t 0.80\n",
            "applications \t 0.79\n",
            "pc \t 0.79\n",
            "\n",
            "\n",
            "      Euclidean        Cosine\n",
            "0     computers     computers\n",
            "1      software      software\n",
            "2    technology    technology\n",
            "3    electronic    electronic\n",
            "4     computing      internet\n",
            "5       devices     computing\n",
            "6      hardware       devices\n",
            "7      internet       digital\n",
            "8  applications  applications\n",
            "9       digital            pc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1.3 Looking at the two lists, does one of the metrics (cosine similarity or euclidean distance) seem to be better than the other?\n",
        "\n",
        "When we look at the closest words from both the metrics they are more or less the same. At this point, there is no clear better metric. Both seem to be selecting similar closest words\n"
      ],
      "metadata": {
        "id": "LlD-Aty8KhwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Analogies\n",
        "\n",
        "One surprising aspect of word embeddings is that the *directions* in the embedding space can be meaningful. For example, some analogy-like relationships like this tend to hold:\n",
        "\n",
        "$$ king - man + woman \\approx queen $$\n",
        "\n",
        "Analogies show us how relationships between pairs of words that is captured in the learned vectors"
      ],
      "metadata": {
        "id": "F3D4X_Q0_uv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = print_closest_words(glove['king'] - glove['man'] + glove['woman'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq_MVbTd-cwz",
        "outputId": "097e834f-fddb-4014-d2dc-c80102468305"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen \t 2.84\n",
            "prince \t 3.66\n",
            "elizabeth \t 3.72\n",
            "daughter \t 3.83\n",
            "widow \t 3.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top result is a reasonable answer like \"queen\",  and the name of the queen of england.\n",
        "\n",
        "We can flip the analogy around and it works:"
      ],
      "metadata": {
        "id": "SObT9dicM8R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = print_closest_words(glove['queen'] - glove['woman'] + glove['man'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCOLWngBM-7O",
        "outputId": "2a6232d5-590f-4f0d-ef38-001a35be9595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "king \t 2.84\n",
            "prince \t 3.25\n",
            "crown \t 3.45\n",
            "knight \t 3.56\n",
            "coronation \t 3.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = print_closest_words(glove['king'] - glove['prince'] + glove['princess'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PbjuVO8M-0g",
        "outputId": "3fa7a8c8-feca-4244-f82b-492efac468d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen \t 3.18\n",
            "king \t 3.91\n",
            "bride \t 4.29\n",
            "lady \t 4.30\n",
            "sister \t 4.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = print_closest_words(glove['uncle'] - glove['man'] + glove['woman'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxG-FQe5M-xT",
        "outputId": "86acba9e-5204-4215-c86f-00407dbd3784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grandmother \t 2.32\n",
            "aunt \t 2.35\n",
            "granddaughter \t 2.36\n",
            "daughter \t 2.40\n",
            "uncle \t 2.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = print_closest_words(glove['grandmother'] - glove['mother'] + glove['father'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV2imC-lM-ue",
        "outputId": "8cb7dafa-b23c-4085-ce9b-689875a3fd11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uncle \t 2.08\n",
            "father \t 2.09\n",
            "grandson \t 2.30\n",
            "nephew \t 2.35\n",
            "elder \t 2.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = print_closest_words(glove['old'] - glove['young'] + glove['father'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3SH9xXJLcD4",
        "outputId": "c31af617-8c26-4420-be83-aaece6b0f423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "father \t 4.03\n",
            "son \t 4.41\n",
            "grandfather \t 4.52\n",
            "grandson \t 4.72\n",
            "daughter \t 4.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also move an embedding towards the direction of \"goodness\" or \"badness\":"
      ],
      "metadata": {
        "id": "5Y3xt9lmNle3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = print_closest_words(glove['good'] - glove['bad'] + glove['programmer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZMiB3USNI_1",
        "outputId": "91031597-de31-4b7d-ed7d-09f3f9f6cbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "versatile \t 4.38\n",
            "creative \t 4.57\n",
            "entrepreneur \t 4.63\n",
            "enables \t 4.72\n",
            "intelligent \t 4.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = print_closest_words(glove['bad'] - glove['good'] + glove['programmer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP_BSsCBNI8n",
        "outputId": "bd0ae51d-f0dd-4395-cb60-b7eafa2b07a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hacker \t 3.84\n",
            "glitch \t 4.00\n",
            "originator \t 4.04\n",
            "hack \t 4.05\n",
            "serial \t 4.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2.1 Consider now the word pair relationships given in Figure 1 below, which comes from Table 1 of the Mikolov [[link](https://arxiv.org/abs/1301.3781)] paper. Choose one of these relationships, but not one of the ones already shown above, and report which one you chose. Write and run code that will generate the second word given the first word. Generate 10 more examples of the same relationship from 10 other words, and comment on the quality of the results.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1O7Zizu63jj5aoZkGkK0sz93CZSEsBDuW)\n",
        "\n"
      ],
      "metadata": {
        "id": "CJjQLdz_OAuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# Choose one of the relationships from the table above and generate 10 examples\n",
        "_ = print_closest_words(glove['athens'] - glove['city'] + glove['country'])\n",
        "print(\"\\n\")\n",
        "_ = print_closest_words(glove['chicago'] - glove['city'] + glove['state'])\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "XgvVPnEvNI5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c733039-c179-494e-8948-41eeacd9e75a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "greece \t 7.59\n",
            "country \t 8.01\n",
            "cyprus \t 8.82\n",
            "greek \t 9.00\n",
            "warned \t 9.11\n",
            "\n",
            "\n",
            "chicago \t 7.81\n",
            "illinois \t 8.00\n",
            "arizona \t 8.04\n",
            "michigan \t 8.13\n",
            "minnesota \t 8.23\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Change Embedding Dimension\n",
        "Now we change the embedding dimension (also known as the vector size) from 50 to 300 and re-run all the examples from above including the new cosini similarity function. Answer the following questions:\n",
        "1.   How does the euclidean distance change between the various words when switching from d=50 to d=300?\n",
        "2.   How does the cosine similarity change?\n",
        "3.   Does the ordering of nearness change?\n",
        "4.   Is it clear that the larger size vectors give better results - why or why not?\n",
        "\n"
      ],
      "metadata": {
        "id": "BhGfRBpRTe05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The first time you run this will download a ~862MB file\n",
        "glove = GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "              dim=300)  # embedding size = 300"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sYqu2QsUcFM",
        "outputId": "c1810a52-f3d3-402e-85be-f2cca5f74a56"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 399999/400000 [01:18<00:00, 5111.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the euclidean distances for embedding dimension of 300"
      ],
      "metadata": {
        "id": "un7HEyyWXgJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = glove['cat']\n",
        "y = glove['dog']\n",
        "torch.norm(y - x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUI6RtqFV3mj",
        "outputId": "8c59f583-929e-4669-fd2a-bc95a7c9f35b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.1959)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = glove['apple']\n",
        "b = glove['orange']\n",
        "torch.norm(b - a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGorX_x-XKf6",
        "outputId": "87c5fb92-e603-45f5-a7b6-5d6ca897cd48"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.1147)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(glove['good'] - glove['bad'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WUnfsbQXMqi",
        "outputId": "068eeae4-3290-4c95-f050-1a1174e08b5d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.8563)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(glove['good'] - glove['water'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZZVevuXPDf",
        "outputId": "ba20b497-0dbf-4dfa-8354-d7532bb41a14"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.5312)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(glove['good'] - glove['well'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KTyY1QdXQna",
        "outputId": "6fe9633a-1556-4611-c20e-d18afa520072"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.0593)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(glove['good'] - glove['perfect'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjbzYjY2XTiy",
        "outputId": "22ddc584-081d-4623-b8f5-62ae0ad0e231"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.2142)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3.1 Compare to the euclidean distances from above (embedding dimension of 50) and answer question 1. How does the euclidean distance change between the various words when switching from d=50 to d=300?\n",
        "\n",
        "Answer: The distances increase. For example the distance between good and bad was 3.31 but now it is 4.85."
      ],
      "metadata": {
        "id": "O5mqAc4oXsPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, lets look at cosine similarity with embedding dimension 300"
      ],
      "metadata": {
        "id": "sF6JaGB5ZzZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = glove['cat']\n",
        "y = glove['dog']\n",
        "torch.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0))"
      ],
      "metadata": {
        "id": "4YQNQ7uhXVh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7495f55-9aad-499b-bbd0-5a7545b032fb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6817])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = glove['apple']\n",
        "b = glove['banana']\n",
        "torch.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0))"
      ],
      "metadata": {
        "id": "-2Du66czYvZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8e96e3-eff7-4d42-97e3-0b9d2a1c16aa"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3924])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['bad'].unsqueeze(0))"
      ],
      "metadata": {
        "id": "lq8JNUnXYvXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb777a3e-1df4-4509-f47e-fd8b3154527e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6445])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['water'].unsqueeze(0))"
      ],
      "metadata": {
        "id": "cyx_hox3ZMJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcc3976-37a9-49ce-b89c-01a48754b969"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3373])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['well'].unsqueeze(0))"
      ],
      "metadata": {
        "id": "TskeONmiYvT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1163d0cb-759d-4e23-b11e-b8612d702d62"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7046])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['good'].unsqueeze(0),\n",
        "                        glove['perfect'].unsqueeze(0))"
      ],
      "metadata": {
        "id": "xdymOV33Y0g0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0571f2bb-723e-4974-ec2b-b5a79309765c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5893])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cosine_similarity(glove['watermelon'].unsqueeze(0),\n",
        "                        glove['aeroplane'].unsqueeze(0))"
      ],
      "metadata": {
        "id": "Y4zmxiCsZPKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321437f5-28fd-4577-b798-28090eb3694f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0955])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3.2 Compare to the cosine similarities from above (embedding dimension of 50) and answer question 2. How does the cosine similarity change when switching from d=50 to d=300?\n",
        "\n",
        "Answer: The cosine similarities values are lower when compared to the embedding dimension of 50"
      ],
      "metadata": {
        "id": "0BXhKAJKZXGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will look at the nearness of words"
      ],
      "metadata": {
        "id": "yG6phX-gZw9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "closest_euclidean_words = print_closest_words(glove['dog'])\n",
        "closest_cosine_words = print_closest_cosine_words(glove['dog'])\n",
        "table = pd.DataFrame()\n",
        "table[\"Euclidean\"] = closest_euclidean_words\n",
        "table[\"Cosine\"] = closest_cosine_words\n",
        "print(table)"
      ],
      "metadata": {
        "id": "UvmbvMpsZWx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c260a363-78f7-412e-ed54-2389ac32f275"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dogs \t 4.36\n",
            "cat \t 5.20\n",
            "pet \t 5.70\n",
            "puppy \t 5.86\n",
            "hound \t 6.22\n",
            "dogs \t 0.79\n",
            "cat \t 0.68\n",
            "pet \t 0.63\n",
            "puppy \t 0.59\n",
            "hound \t 0.55\n",
            "  Euclidean Cosine\n",
            "0      dogs   dogs\n",
            "1       cat    cat\n",
            "2       pet    pet\n",
            "3     puppy  puppy\n",
            "4     hound  hound\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3.3 Compare to the near words from above (embedding dimension of 50) and answer question 3. Does the ordering of nearness words change?\n",
        "\n",
        "Answer: Yes, the ordering changes dogs is now higher than cat, pet is also higher than before."
      ],
      "metadata": {
        "id": "XPaBRJ5laDoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3.4 Is it clear that the larger size vectors give better results - why or why not?\n",
        "\n",
        "Answer: THe larger size is giving us better results (not by much in this example), but there is an improvement. \"dogs\" is now the closest to dog rather than cat which was before. \"hound\" also makes it to the top 5 list which is intuitively closer to dog than rabbit or horse which were included first. \\\\\n",
        "In general, larger embeddings (e.g., 300 dimensions vs. 50 dimensions) have the potential to capture more nuanced semantic relationships between words. This can lead to better performance on tasks requiring a deep understanding of word meanings and contexts. It is important to note that while increasing the embedding size can improve performance, the gains may diminish beyond a certain point. For instance, the improvement from 50 to 300 dimensions might be substantial, but the improvement from 200 to 300 dimensions might be marginal."
      ],
      "metadata": {
        "id": "LvGCAct7aWhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. (Optional): Computing Meaning from Word Embeddings\n",
        "\n",
        "Now that we’ve seen some of the power of word embeddings, we can also feel the frustration that the individual elements/numbers in each word vector do not have a meaning that can be interpreted or understood by humans. It would have preferable that each position in the vector correspond to a specific axis of meaning that we can understand based on our ability to comprehend language.\n",
        "\n",
        "For example the \"amount\" the word related to *colour* or *temperature* or *politics*. This is not the case, because the numbers are the result of an optmization process that does not drive each vector element toward human-understandable meaning.\n",
        "\n",
        "We can, however, make use of the methods shown in Section 1 above to measure the amount of meaning in specific categories of our choosing, such as colour. Suppose that we want to know how much a particular word/embedding relates to colour. One way to measure that could be to determine the cosine similarity between the word embedding for colour and the word of interest. We might expect that a word like ‘sky’ or ‘grass’ might have elements of colour in it, and that ‘purple’ would have more. However, it may also be true that there are multiple meanings to a single word, such as ‘colour’, and so it might be better to define a category of meaning by using several words that, all together, define it with more precision.\n",
        "\n",
        "For example, a way to define a category such as colour would be to use that word itself, and to- gether with several examples, such ‘red’, ‘green’, ‘blue’, ‘yellow.’ Then, to measure the “amount” of colour in a specific word (like ‘sky’) you could compute the average cosine similarity between sky and each of the words in the category. Alternatively, you could average the vectors of all the words in the category, and compute the cosine similarity between the embedding of sky and that average embedding. In this section, use the d=50 GlOVe embeddings that you used in Section 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "B7KhVUtzaJNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe embeddings using torchtext\n",
        "glove = GloVe(name='6B', dim=50)\n",
        "embedding_size = 50  # Size of GloVe embeddings"
      ],
      "metadata": {
        "id": "2VyMjlrdunHu"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1\n",
        "Write a PyTorch-based function called compare words to category that takes as input:\n",
        "* The meaning category given by a set of words (as discussed above) that describe the category, and\n",
        "* A given word to ‘measure’ against that category.\n",
        "\n",
        "\n",
        "The function should compute the cosine similarity of the given word in the category in two ways: \\\\\n",
        "(a) By averaging the cosine similarity of the given word with every word in the category, and \\\\\n",
        "(b) By computing the cosine similarity of the word with the average embedding of all of the words in the category."
      ],
      "metadata": {
        "id": "pEzXXUcbrmyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a word to its embedding\n",
        "def word_to_embedding(word, glove):\n",
        "    if word in glove.stoi:\n",
        "        return glove[word]\n",
        "    else:\n",
        "        return torch.zeros(embedding_size)\n",
        "\n",
        "def compare_words_to_category(word, category_words, glove):\n",
        "    word_embedding = word_to_embedding(word, glove).unsqueeze(0)\n",
        "    category_embeddings = torch.stack([word_to_embedding(w, glove) for w in category_words])\n",
        "\n",
        "    # Method (a): Average cosine similarity of the given word with every word in the category\n",
        "    cosine_similarities = torch.cosine_similarity(word_embedding, category_embeddings, dim=1) # TODO\n",
        "    avg_cosine_similarity = cosine_similarities.mean().item()\n",
        "\n",
        "    # Method (b): Cosine similarity of the word with the average embedding of the category words\n",
        "    avg_category_embedding = category_embeddings.mean(dim=0, keepdim=True) # TODO\n",
        "    avg_category_cosine_similarity = torch.cosine_similarity(word_embedding, avg_category_embedding).item()\n",
        "\n",
        "    return avg_cosine_similarity, avg_category_cosine_similarity"
      ],
      "metadata": {
        "id": "_9nVGRP5rBGk"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2\n",
        "Let’s define the colour meaning category using these words: “colour”, “red”, “green”, “blue”, “yellow.” Compute the similarity (using both methods (a) and (b) above) for each of these words: “greenhouse”, “sky”, “grass”, “purple”, “scissors”, “microphone”, “president” and present them in a table."
      ],
      "metadata": {
        "id": "mwXCdy1LtD2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_words = [\"colour\", \"red\", \"green\", \"blue\", \"yellow\"]\n",
        "words_to_measure = [\"greenhouse\", \"sky\", \"grass\", \"purple\", \"scissors\",\n",
        "                    \"microphone\", \"president\"]\n",
        "\n",
        "results = []\n",
        "for word in words_to_measure:\n",
        "    avg_cosine_similarity, avg_category_cosine_similarity = compare_words_to_category(word, category_words, glove) # TODO\n",
        "    results.append((word, avg_cosine_similarity, avg_category_cosine_similarity))\n",
        "\n",
        "# Create a DataFrame to present the results in a table\n",
        "df_results = pd.DataFrame(results, columns=[\"Word\", \"Avg Cosine Similarity\", \"Cosine Similarity with Avg Embedding\"])\n",
        "print(df_results)"
      ],
      "metadata": {
        "id": "ZYMC0BtltHFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2555de8c-a1a8-438f-9dc6-1e228e2379dd"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Word  Avg Cosine Similarity  Cosine Similarity with Avg Embedding\n",
            "0  greenhouse               0.183072                              0.201687\n",
            "1         sky               0.601871                              0.670239\n",
            "2       grass               0.506045                              0.557923\n",
            "3      purple               0.799313                              0.888739\n",
            "4    scissors               0.289022                              0.320292\n",
            "5  microphone               0.307690                              0.343096\n",
            "6   president               0.298648                              0.329170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.1 Do the results for each method make sense? Why or why not? What is the apparent difference between method 1 and 2?\n",
        "\n",
        "Answer: \\\\\n",
        "Method 1: Average Cosine Similarity with Every Word in the Category\\\\\n",
        "This method calculates the cosine similarity of the given word with each word in the category and then averages these similarities. It reflects how the given word is similar to each individual word in the category.\n",
        "\n",
        "Method 2: Cosine Similarity with the Average Embedding of the Category Words \\\\\n",
        "This method calculates the average embedding of the category words and then computes the cosine similarity between the given word and this average embedding. It reflects how the given word is similar to the overall concept represented by the category.\n",
        "\n",
        "\"Purple\" has very high similarity in both methods because it is directly a color.\n",
        "\n",
        "\"President\" shows low similarity, which is expected as it is not related to colors."
      ],
      "metadata": {
        "id": "KFc9BntQubV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Training A Word Embedding Using the Skip-Gram Method on a Small Corpus\n",
        "\n",
        "So far in this notebook we've used the pre-trained GloVe embeddings. The lecture this morning described the Skip Gram method of training word embeddings. In this section you are going to review code to use that method to train a very small embedding, for a very small vocabulary on a very small corpus of text. The goal is to gain some insight into the general notion of how embeddings are produced. The corpus you are going to use is in the file SmallSimpleCorpus.txt, and was also shown in the lecture.\n",
        "\n",
        "NOTE: First we need to upload the file SmallSimpleCorpus.txt to the Colab environment. Download the data files from lab_5_1 folder on the github page and then navigate to the folder icon on the left hand side of this page and click the \"upload to session storage\" button to upload the data files to the colab session."
      ],
      "metadata": {
        "id": "moAuiKpZazXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy"
      ],
      "metadata": {
        "id": "whMJrpncbpAV"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SpaCy's English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "vPGnmHKPnvEJ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, read the file SmallSimpleCorpus.txt so that you see what the sequence of sentences is. Recalling the notion “you shall know a word by the company it keeps,” find three pairs of words that this corpora implies have similar or related meanings. For example, ‘he’ and ‘she’ are one such example – which you cannot use in your answer!\n",
        "\n",
        "Answer: a-the, rub-hold, dog-cat"
      ],
      "metadata": {
        "id": "tzqJDqfqn1uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file to colab and read in the corpus\n",
        "with open('./SmallSimpleCorpus.txt', 'r') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "# Preprocess the text\n",
        "def prepare_texts(corpus):\n",
        "    doc = nlp(corpus)\n",
        "    lemmas = [token.lemma_ for token in doc if token.is_alpha]\n",
        "    return lemmas"
      ],
      "metadata": {
        "id": "91-JsD1_oNex"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the prepare_texts function in the code given to you fulfills several key functions in text processing, a little bit simplified for this simple corpus. Rather than full tokenization it only lemmatizes the corpus,\n",
        "which means converting words to their root - for example the word “holds” becomes “hold”, whereas the word  “hold” itself stays the same.\n",
        "The prepare_texts function performs lemmatization using the [spaCy](https://spacy.io/models/en) library.\n",
        "Review the code of prepare_texts to make sure you understand what it is doing. Review the code that reads the corpus SmallSimpleCorpus.txt, and run the prepare_texts on it to return the text (lemmas) that will be used next.\n"
      ],
      "metadata": {
        "id": "zXaIvfftowCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lematize the corpus and create the vocabulary\n",
        "lemmas = prepare_texts(corpus) #TODO\n",
        "vocab = set(lemmas)\n",
        "v2i = {v: i for i, v in enumerate(vocab)} # dictionary to lookup word to index\n",
        "i2v = {i: v for v, i in v2i.items()} # dictionary to lookup index to word"
      ],
      "metadata": {
        "id": "_kljxBXuoPxk"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that the vocabulary size is 11. \\\\\n",
        "\n",
        "What purpose do the v2i and i2v dictionaries serve?\n",
        "Answer: v2i helps us to lookup the index of every word and i2v helps us lookup the word given it's index"
      ],
      "metadata": {
        "id": "jP-g4libpqa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO\n",
        "len(vocab)"
      ],
      "metadata": {
        "id": "N1-zfe8TpvQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a5e574-63c0-4717-825b-93b36ec5fc74"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `tokenize_and_preprocess_text` takes the lemmatized small corpus as input, along with `v2i` (which serves as a simple, lemma-based tokenizer) and a window size window. Its output should be the Skip Gram training dataset for this corpus: pairs of words in the corpus that “belong” together, in the Skip Gram sense.\n",
        "That is, for every word in the corpus a set of training examples are generated with that word serving as the (target) input to the predictor,\n",
        "and all the words that fit within a window of size window surrounding the word would be predicted to be in the “context” of the given word.\n",
        "The words are expressed as tokens (numbers).\n",
        " Add a little code so that you can see the dataset that is produced."
      ],
      "metadata": {
        "id": "66Ois3z7qS9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and preprocess the text\n",
        "def tokenize_and_preprocess_text(lemmas, v2i, window=3):\n",
        "    data = []\n",
        "    for i in range(len(lemmas)):\n",
        "        target = v2i[lemmas[i]]\n",
        "        context = []\n",
        "        for j in range(i - window // 2, i + window // 2 + 1):\n",
        "            if j != i and j >= 0 and j < len(lemmas):\n",
        "                context.append(v2i[lemmas[j]])\n",
        "        for c in context:\n",
        "            data.append((target, c))\n",
        "    return data"
      ],
      "metadata": {
        "id": "52WgB7prqPIY"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Skip gram dataset with window size of 5\n",
        "window_size = 5# TODO\n",
        "data = tokenize_and_preprocess_text(lemmas, v2i, window_size)# TODO\n"
      ],
      "metadata": {
        "id": "KOZ_-mqYqQNF"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Review the code in Word2vecModel. Part of this model ultimately provides the trained embeddings/vectors, and you can see these are defined and initialized to random numbers in the line `self.embedding = torch.nn.Parameter(torch.rand(\n",
        "            vocab_size, embedding_size))`"
      ],
      "metadata": {
        "id": "cyQIHdXssbI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Word2Vec model\n",
        "class Word2VecModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super(Word2VecModel, self).__init__()\n",
        "        self.embedding = torch.nn.Parameter(torch.rand(\n",
        "            vocab_size, embedding_size))\n",
        "        self.fc = nn.Linear(embedding_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding[x]\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tUti3LGZsZLH"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the vocab size\n",
        "vocab_size = len(vocab) # TODO\n",
        "embedding_size = 2 # Size of the embedding vector\n",
        "# Initialize the Word2Vec model\n",
        "model = Word2VecModel(vocab_size, embedding_size) # TODO"
      ],
      "metadata": {
        "id": "1SrHFoHns34Z"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Review the code for training the model. It uses Cross Entropy loss function described in the lecture, a batch size of 4, a window size of 5, and 50 Epochs of training. It uses the Adam optimizer, and a learning rate of 0.001."
      ],
      "metadata": {
        "id": "Su1mTcsFtWKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "def train_word2vec(model, data, epochs=50, batch_size=4, learning_rate=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        np.random.shuffle(data)\n",
        "        losses = []\n",
        "        for i in range(0, len(data), batch_size):\n",
        "            batch = data[i:i+batch_size]\n",
        "            inputs, labels = zip(*batch)\n",
        "            inputs = torch.tensor(inputs, dtype=torch.long)\n",
        "            labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {np.mean(losses):.4f}')\n",
        "\n",
        "train_word2vec(model, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXQOkAgkgCs3",
        "outputId": "f743ede0-e9b9-45f5-d4b6-403df3615c7b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.4374\n",
            "Epoch 2, Loss: 2.3822\n",
            "Epoch 3, Loss: 2.3753\n",
            "Epoch 4, Loss: 2.3716\n",
            "Epoch 5, Loss: 2.3683\n",
            "Epoch 6, Loss: 2.3647\n",
            "Epoch 7, Loss: 2.3615\n",
            "Epoch 8, Loss: 2.3582\n",
            "Epoch 9, Loss: 2.3552\n",
            "Epoch 10, Loss: 2.3522\n",
            "Epoch 11, Loss: 2.3502\n",
            "Epoch 12, Loss: 2.3479\n",
            "Epoch 13, Loss: 2.3455\n",
            "Epoch 14, Loss: 2.3432\n",
            "Epoch 15, Loss: 2.3415\n",
            "Epoch 16, Loss: 2.3394\n",
            "Epoch 17, Loss: 2.3377\n",
            "Epoch 18, Loss: 2.3361\n",
            "Epoch 19, Loss: 2.3347\n",
            "Epoch 20, Loss: 2.3332\n",
            "Epoch 21, Loss: 2.3320\n",
            "Epoch 22, Loss: 2.3309\n",
            "Epoch 23, Loss: 2.3298\n",
            "Epoch 24, Loss: 2.3287\n",
            "Epoch 25, Loss: 2.3278\n",
            "Epoch 26, Loss: 2.3268\n",
            "Epoch 27, Loss: 2.3260\n",
            "Epoch 28, Loss: 2.3253\n",
            "Epoch 29, Loss: 2.3247\n",
            "Epoch 30, Loss: 2.3242\n",
            "Epoch 31, Loss: 2.3239\n",
            "Epoch 32, Loss: 2.3235\n",
            "Epoch 33, Loss: 2.3234\n",
            "Epoch 34, Loss: 2.3231\n",
            "Epoch 35, Loss: 2.3232\n",
            "Epoch 36, Loss: 2.3229\n",
            "Epoch 37, Loss: 2.3227\n",
            "Epoch 38, Loss: 2.3230\n",
            "Epoch 39, Loss: 2.3226\n",
            "Epoch 40, Loss: 2.3227\n",
            "Epoch 41, Loss: 2.3224\n",
            "Epoch 42, Loss: 2.3226\n",
            "Epoch 43, Loss: 2.3225\n",
            "Epoch 44, Loss: 2.3227\n",
            "Epoch 45, Loss: 2.3227\n",
            "Epoch 46, Loss: 2.3224\n",
            "Epoch 47, Loss: 2.3224\n",
            "Epoch 48, Loss: 2.3222\n",
            "Epoch 49, Loss: 2.3224\n",
            "Epoch 50, Loss: 2.3222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below that displays each of the embeddings in a 2-dimensional plot using Matplotlib.\n"
      ],
      "metadata": {
        "id": "BcJMpAzrvC--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the embeddings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_embeddings(model, i2v):\n",
        "    embeddings = model.embedding.data.numpy()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, word in i2v.items():\n",
        "        x, y = embeddings[i]\n",
        "        plt.scatter(x, y)\n",
        "        plt.text(x + 0.02, y + 0.02, word, fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "plot_embeddings(model, i2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "HjUiXq6chAnO",
        "outputId": "124e8150-b14b-4515-a6bd-712888179e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the results make sense, and confirm your choices from part 1 of this Section?\n",
        "Answer: Yes the similar context words do appear to closer in the 2-dimensional embedded space\n",
        "\n",
        "What would happen when the window size is too large?\n",
        "Answer: A larger window size means that more distant words are considered as context words. While nearby words are often strongly related to the target word, more distant words might not be as closely related, introducing noise into the training data. This can make the model less effective at capturing meaningful relationships between words.\n",
        "\n",
        "At what value would window become too large for this corpus?\n",
        "Answer: Anything window size larger than 7. This is because our sentences are 5-10 words and if we have a larger than 7 window we would be creating many context pairs across distant words."
      ],
      "metadata": {
        "id": "CRYB0G7tvSxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training A Single-Neuron Classifier to Determine if a Sentence is Objective or Subjective\n",
        "\n",
        "The purpose of this exercise is to review the code for training a simple network (just a single neuron) to determine if a sentence is objective or subjective."
      ],
      "metadata": {
        "id": "73X6qkEznL_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qh5A_xW2HuO",
        "outputId": "36079f69-7a9d-4791-e060-e9f78110c4e6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.1 (from gradio)\n",
            "  Downloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=1417d4033e44e729a84657f1e7592774e0311dcecbb96a2dc8a830bd2b4a96cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.5 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.9 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from torchtext.vocab import GloVe\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nkW2BxazxnED"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file data.tsv in colab and Load the data\n",
        "df = pd.read_csv('data.tsv', sep='\\t', header=None, names=['sentence', 'label'])\n",
        "df = df.loc[1:]"
      ],
      "metadata": {
        "id": "p9fZDTPnwGZy"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a quick look at the file data.tsv to see which sentences were labelled subjective (1) and which objective (0). (The 1’s are in the first half of the file)"
      ],
      "metadata": {
        "id": "GuxuwOWDwmsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read through each of the code blocks, getting a rough sense of what is going on by reading the comments.\n",
        "You see code functions that split the dataset, in the tab-separated file data.tsv into training, validation and test sets.\n",
        "Perhaps look closest at the code block call “Classifier model” class where you can see the torch.nn.Linear class being used to instantiate a single neuron with embedding_size inputs and just 1 output."
      ],
      "metadata": {
        "id": "lY1VMmgL5EPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SpaCy's English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load GloVe embeddings using torchtext\n",
        "glove = GloVe(name='6B', dim=50)\n",
        "embedding_size = 50  # Size of GloVe embeddings\n",
        "\n",
        "# Function to convert a sentence to an embedding by averaging word embeddings\n",
        "def sentence_to_embedding(sentence, glove):\n",
        "    tokens = [token.text for token in nlp(sentence) if token.is_alpha]\n",
        "    embeddings = [glove[token] for token in tokens if token in glove.stoi]\n",
        "    if embeddings:\n",
        "        return torch.mean(torch.stack(embeddings), dim=0)\n",
        "    else:\n",
        "        return torch.zeros(embedding_size)\n",
        "\n",
        "# Convert all sentences to embeddings at once\n",
        "def convert_sentences_to_embeddings(sentences, glove):\n",
        "    embeddings = [sentence_to_embedding(sentence, glove) for sentence in sentences]\n",
        "    return torch.stack(embeddings)\n",
        "\n",
        "# Splitting the data into train, validation, and test sets\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
        "    df['sentence'], df['label'], test_size=0.2, random_state=42)\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
        "    train_sentences, train_labels, test_size=0.125, random_state=42)  # 0.125 * 0.8 = 0.1\n",
        "\n",
        "train_embeddings = convert_sentences_to_embeddings(train_sentences, glove)\n",
        "val_embeddings = convert_sentences_to_embeddings(val_sentences, glove)\n",
        "test_embeddings = convert_sentences_to_embeddings(test_sentences, glove)"
      ],
      "metadata": {
        "id": "2y6wogi63BKP"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding = self.embeddings[idx]\n",
        "        label = self.labels[idx]\n",
        "        return embedding, torch.tensor(float(label), dtype=torch.float32)\n",
        "\n",
        "# Convert to dataset\n",
        "train_dataset = TextDataset(train_embeddings, train_labels.tolist())\n",
        "val_dataset = TextDataset(val_embeddings, val_labels.tolist())\n",
        "test_dataset = TextDataset(test_embeddings, test_labels.tolist())\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "1OToKZZs9vpx"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the classifier model\n",
        "class ClassifierModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ClassifierModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return torch.sigmoid(x)\n"
      ],
      "metadata": {
        "id": "5976y14B6BYb"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the model\n",
        "model = ClassifierModel(embedding_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        batch_train_losses = []\n",
        "        for embeddings, labels in train_loader:\n",
        "            labels = labels.view(-1, 1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(embeddings)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_train_losses.append(loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        batch_val_losses = []\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for embeddings, labels in val_loader:\n",
        "                labels = labels.view(-1, 1)\n",
        "\n",
        "                outputs = model(embeddings)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                batch_val_losses.append(loss.item())\n",
        "\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = np.mean(batch_train_losses)\n",
        "        val_loss = np.mean(batch_val_losses)\n",
        "        val_accuracy = correct / total\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    return train_losses, val_losses, val_accuracies\n",
        "\n",
        "num_epochs = 20\n",
        "train_losses, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
        "\n",
        "# Plotting training and validation losses\n",
        "plt.figure(figsize=(5, 2.5))\n",
        "plt.plot(range(num_epochs), train_losses, label='Training Loss')\n",
        "plt.plot(range(num_epochs), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting validation accuracy\n",
        "plt.figure(figsize=(5, 2.5))\n",
        "plt.plot(range(num_epochs), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Define the function to evaluate the model\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for embeddings, labels in test_loader:\n",
        "            labels = labels.view(-1, 1)\n",
        "\n",
        "            outputs = model(embeddings)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_losses.append(loss.item())\n",
        "\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Loss: {np.mean(test_losses):.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print(\"\\n\")\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "8_-EzPeB2ZeE",
        "outputId": "6522fb38-3ccc-4b5f-e953-600e672f63cf"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 0.6847, Validation Loss: 0.6677, Validation Accuracy: 0.7290\n",
            "Epoch 2, Training Loss: 0.6507, Validation Loss: 0.6342, Validation Accuracy: 0.8180\n",
            "Epoch 3, Training Loss: 0.6202, Validation Loss: 0.6043, Validation Accuracy: 0.8460\n",
            "Epoch 4, Training Loss: 0.5931, Validation Loss: 0.5776, Validation Accuracy: 0.8640\n",
            "Epoch 5, Training Loss: 0.5692, Validation Loss: 0.5539, Validation Accuracy: 0.8670\n",
            "Epoch 6, Training Loss: 0.5476, Validation Loss: 0.5325, Validation Accuracy: 0.8720\n",
            "Epoch 7, Training Loss: 0.5283, Validation Loss: 0.5134, Validation Accuracy: 0.8760\n",
            "Epoch 8, Training Loss: 0.5111, Validation Loss: 0.4963, Validation Accuracy: 0.8790\n",
            "Epoch 9, Training Loss: 0.4957, Validation Loss: 0.4807, Validation Accuracy: 0.8810\n",
            "Epoch 10, Training Loss: 0.4815, Validation Loss: 0.4666, Validation Accuracy: 0.8830\n",
            "Epoch 11, Training Loss: 0.4690, Validation Loss: 0.4538, Validation Accuracy: 0.8850\n",
            "Epoch 12, Training Loss: 0.4575, Validation Loss: 0.4421, Validation Accuracy: 0.8860\n",
            "Epoch 13, Training Loss: 0.4468, Validation Loss: 0.4317, Validation Accuracy: 0.8870\n",
            "Epoch 14, Training Loss: 0.4374, Validation Loss: 0.4217, Validation Accuracy: 0.8870\n",
            "Epoch 15, Training Loss: 0.4284, Validation Loss: 0.4129, Validation Accuracy: 0.8880\n",
            "Epoch 16, Training Loss: 0.4206, Validation Loss: 0.4045, Validation Accuracy: 0.8890\n",
            "Epoch 17, Training Loss: 0.4129, Validation Loss: 0.3970, Validation Accuracy: 0.8870\n",
            "Epoch 18, Training Loss: 0.4062, Validation Loss: 0.3899, Validation Accuracy: 0.8890\n",
            "Epoch 19, Training Loss: 0.4001, Validation Loss: 0.3833, Validation Accuracy: 0.8900\n",
            "Epoch 20, Training Loss: 0.3937, Validation Loss: 0.3775, Validation Accuracy: 0.8870\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x250 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAEFCAYAAABjIqe9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP4UlEQVR4nO3deXxM9/7H8ddM9j2RfbMnBBEEKVpF1dYqrZaqEi1VLrr6Vd0W1c1ttb1uy6XttbTV1nZtt3Zq33cJEUtJkE2QXbaZ8/vjyDCSiYgkk/B5Ph7zaOac7znnO6eTvH3P+Z7vV6MoioIQQgghSqQ1dwWEEEKI6kyCUgghhCiFBKUQQghRCglKIYQQohQSlEIIIUQpJCiFEEKIUkhQCiGEEKWQoBRCCCFKIUEphBBClEKCUgghhChFtQjKmTNnUrduXWxtbYmIiGD//v0my3bq1AmNRlPs9dRTT1VhjYUQQjwszB6UixYt4p133mHy5MkcPnyYsLAwunfvTkpKSonlly1bRmJiouEVHR2NhYUFL7zwQhXXXAghxMNAY+5B0SMiImjTpg0zZswAQK/XExgYyNixY3n//ffvuv306dOZNGkSiYmJODg4VHZ1hRBCPGQszXnw/Px8Dh06xIQJEwzLtFotXbt2Zc+ePWXax5w5c3jxxRdNhmReXh55eXmG93q9nmvXruHu7o5Go7m/DyCEEKLGUhSFzMxM/Pz80GpNX2A1a1Cmpqai0+nw9vY2Wu7t7c2pU6fuuv3+/fuJjo5mzpw5JstMnTqVKVOm3HddhRBCPJguXrxIQECAyfVmDcr7NWfOHEJDQ2nbtq3JMhMmTOCdd94xvE9PT6d27dpcvHgRZ2fnqqimEEKIaigjI4PAwECcnJxKLWfWoPTw8MDCwoLk5GSj5cnJyfj4+JS6bXZ2NgsXLuTjjz8utZyNjQ02NjbFljs7O0tQCiGEuOttOLP2erW2tiY8PJzNmzcblun1ejZv3ky7du1K3XbJkiXk5eXx8ssvV3Y1hRBCPMTMfun1nXfeITIyktatW9O2bVumT59OdnY2r7zyCgBDhgzB39+fqVOnGm03Z84c+vbti7u7uzmqLYQQ4iFh9qAcMGAAV65cYdKkSSQlJdGiRQvWrVtn6OATHx9frDdSbGwsO3fuZMOGDeaoshBCiIeI2Z+jrGoZGRm4uLiQnp4u9yiFqCZ0Oh0FBQXmroZ4wFhZWWFhYWFyfVnzwOwtyprqdHImtRys8XAs3lFICFE2iqKQlJREWlqauasiHlCurq74+Pjc13PzEpTlEHUpncFz9+HjbMvCEY/gam9t7ioJUSMVhaSXlxf29vYyCIioMIqikJOTYxgO1dfXt9z7kqAsB0dbSyy1Wk4lZRI57wALhrXFydbK3NUSokbR6XSGkJROeaIy2NnZAZCSkoKXl1epl2FLY/ZB0Wuieh4O/Do8Ajd7K45dTGPYTwe5ka8zd7WEqFGK7kna29ubuSbiQVb0/bqfe+ASlOXUyMeJn1+NwMnGkv3nrzHil4PkFUpYCnGv5HKrqEwV8f2SoLwPoQEuzHulDXZWFuw4k8qY345QoNObu1pCCCEqkATlfWpdtxb/iWyNtaWWjSeTeXfxMXT6h+qJGyFEBahbty7Tp08vc/mtW7ei0Wikx3AVkKCsAB0aejD75VZYajWsOpbA35dFoZewFOKBpNFoSn199NFH5drvgQMHGDFiRJnLt2/fnsTERFxcXMp1vLKSQJZerxWmS2Nv/vViS8b+fphFBy9iZ23B5N5N5P6LEA+YxMREw8+LFi1i0qRJxMbGGpY5OjoaflYUBZ1Oh6Xl3f/Uenp63lM9rK2t7zp5hKgY0qKsQE819+XL58MAmL/7AtPWx95lCyFETePj42N4ubi4oNFoDO9PnTqFk5MTa9euJTw8HBsbG3bu3Mm5c+fo06cP3t7eODo60qZNGzZt2mS03zsvvWo0Gv7zn//w7LPPYm9vT1BQEKtWrTKsv7OlN3/+fFxdXVm/fj0hISE4OjrSo0cPo2AvLCzkjTfewNXVFXd3d8aPH09kZCR9+/Yt9/m4fv06Q4YMwc3NDXt7e3r27MmZM2cM6+Pi4ujduzdubm44ODjQtGlT1qxZY9h20KBBeHp6YmdnR1BQEPPmzSt3XSqLBGV5HfkV4vcVW/x8eACf9G0GwL+3nmPmlrNVXTMhaixFUcjJLzTLqyJH83z//ff5xz/+QUxMDM2bNycrK4tevXqxefNmjhw5Qo8ePejduzfx8fGl7mfKlCn079+f48eP06tXLwYNGsS1a9dMls/JyeGrr77il19+Yfv27cTHxzNu3DjD+i+++IJff/2VefPmsWvXLjIyMlixYsV9fdahQ4dy8OBBVq1axZ49e1AUhV69ehkexxg9ejR5eXls376dqKgovvjiC0Ore+LEiZw8eZK1a9cSExPDrFmz8PDwuK/6VAa59Foep9bAyr+BjTMMXgEB4UarBz9Shxv5hXy+5hTT1sdia2XBsEfrmaeuQtQgNwp0NJm03izHPvlxd+ytK+ZP4scff8yTTz5peF+rVi3CwsIM7z/55BOWL1/OqlWrGDNmjMn9DB06lIEDBwLw+eef8+2337J//3569OhRYvmCggJmz55NgwYNABgzZozRnL3fffcdEyZM4NlnnwVgxowZhtZdeZw5c4ZVq1axa9cu2rdvD8Cvv/5KYGAgK1as4IUXXiA+Pp5+/foRGhoKQP369Q3bx8fH07JlS1q3bg2orerqSFqU5VG/E9R5FPIyYMGzkHC0WJERHRvwVtcgAD754yS/7y/9X45CiAdH0R/+IllZWYwbN46QkBBcXV1xdHQkJibmri3K5s2bG352cHDA2dnZMCRbSezt7Q0hCeqwbUXl09PTSU5Opm3btob1FhYWhIeHF9tPWcXExGBpaUlERIRhmbu7O40aNSImJgaAN954g08//ZQOHTowefJkjh8/big7atQoFi5cSIsWLXjvvffYvXt3uetSmaRFWR7W9vDSIljwHFzcB7/0hcg/wKeZUbE3nwgiJ1/HD9v/4u/Lo7CzsqBvS3/z1FmIGsDOyoKTH3c327ErioODg9H7cePGsXHjRr766isaNmyInZ0dzz//PPn5+aXux8rKeGhMjUaDXm/6We2Sypt7gqjhw4fTvXt3Vq9ezYYNG5g6dSpff/01Y8eOpWfPnsTFxbFmzRo2btzIE088wejRo/nqq6/MWuc7SYuyvGwcYdAS8A+HG9fh5z6QcsqoiEajYULPxrz8SG0UBd5dcox10UlmqrAQ1Z9Go8He2tIsr8rsob5r1y6GDh3Ks88+S2hoKD4+Ply4cKHSjlcSFxcXvL29OXDggGGZTqfj8OHD5d5nSEgIhYWF7Nt3q7/G1atXiY2NpUmTJoZlgYGBjBw5kmXLlvHuu+/y448/GtZ5enoSGRnJggULmD59Oj/88EO561NZpEV5P2xd4OX/wk/PQNJx+PkZGLoGPBoaimg0Gj5+phk38vX89/Alxv5+mB+HtKZTIy8zVlwIUZWCgoJYtmwZvXv3RqPRMHHixFJbhpVl7NixTJ06lYYNG9K4cWO+++47rl+/XqZ/JERFReHk5GR4r9FoCAsLo0+fPrz22mt8//33ODk58f777+Pv70+fPn0AeOutt+jZsyfBwcFcv36dLVu2EBISAsCkSZMIDw+nadOm5OXl8ccffxjWVSfSorxfdm4wZCV4NYWsZPipN1z7y6iIVqvhi36hPBXqS4FO4fVfDrH3r6tmqrAQoqp98803uLm50b59e3r37k337t1p1apVlddj/PjxDBw4kCFDhtCuXTscHR3p3r07tra2d922Y8eOtGzZ0vAqurc5b948wsPDefrpp2nXrh2KorBmzRrDZWCdTsfo0aMJCQmhR48eBAcH8+9//xtQnwWdMGECzZs3p2PHjlhYWLBw4cLKOwHlpFHMfQG7ipV1Rut7lnUFfnoarpwCl0B4ZQ241jYqkl+oZ+SCQ/x5KgUHawt+GR5Bq9puFVcHIWqQ3Nxczp8/T7169cr0h1pUPL1eT0hICP379+eTTz4xd3UqRWnfs7LmgbQoK4qjp9qydG8I6RfVlmX6ZaMi1pZa/j2oFe0buJOdr2Po3P2cSEg3U4WFEA+buLg4fvzxR06fPk1UVBSjRo3i/PnzvPTSS+auWrUmQVmRnHwg8n/gVheuX1DDMtO4846tlQU/DmlNeB03MnILGTxnP2dTMs1SXSHEw0Wr1TJ//nzatGlDhw4diIqKYtOmTdXyvmB1IkFZ0Zz91LB0qQ3XzqkdfbKuGBVxsLFk3ittaObvzLXsfF76cR/nU7PNVGEhxMMiMDCQXbt2kZ6eTkZGBrt376Zjx47mrla1J0FZGVxrQ+QqcPaH1Fj10ZEc42GnnG2t+PnVCIK9HUnJzOOF2XuIScwwU4WFEEKYIkFZWWrVU1uWjj6QckINyxvXjYs4WPPr8EcI8XUmNSuPAd/v4XD8dRM7FEIIYQ4SlJXJvYHasnTwVJ+z/OU5yDXuvOPpZMPC1x6hVW1XMnILefk/+9h5JtVMFRZCCHEnCcrK5tlI7Q1rVwsSDsOvL0CececdF3srFgyP4LEgD3Lydbw6/4CM4COEENWEBGVV8G4KQ1aoI/lc3Ae/DYB848479taW/CeyNT2b+ZCv0/O3Xw+x9NAl89RXCCGEgQRlVfENg8HL1am54nbB7wOh4IZRERtLC74b2JLnwwPQKzBuyTHm7TpvpgoLIYQACcqq5R+ujg1r7Qjnt8Gil6Ewz6iIpYWWL/s159UO6vyVU/53km83nzH7DABCiIrVqVMn3nrrLcP7unXrMn369FK30Wg09z3RckXu52EhQVnVAtvCS4vByh7OboLFkVBoPNWOVqth4tMhvN01GIBvNp7m09UxEpZCVAO9e/c2OXHyjh070Gg0RnMultWBAwcYMWLE/VbPyEcffUSLFi2KLU9MTKRnz54Veqw7zZ8/H1dX10o9RlWRoDSHuh1g4EKwtIXTa+G/w0BXYFREo9HwZtcgJj2tTlUzZ+d5xv/3ODq9hKUQ5jRs2DA2btzIpUvF+xDMmzeP1q1bG024XFaenp7Y29tXRBXvysfHBxsbmyo51oNAgtJc6j8OL/4KFtYQswoWDyl2zxLg1Ufr8dULYWg1sPigOk1XXqHODBUWQgA8/fTTeHp6Mn/+fKPlWVlZLFmyhGHDhnH16lUGDhyIv78/9vb2hIaG8vvvv5e63zsvvZ45c4aOHTtia2tLkyZN2LhxY7Ftxo8fT3BwMPb29tSvX5+JEydSUKD+o3v+/PlMmTKFY8eOodFo0Gg0hjrfeek1KiqKLl26YGdnh7u7OyNGjCArK8uwfujQofTt25evvvoKX19f3N3dGT16tOFY5REfH0+fPn1wdHTE2dmZ/v37k5ycbFh/7NgxOnfujJOTE87OzoSHh3Pw4EFAHbO2d+/euLm54eDgQNOmTVmzZk2563I3Mh+lOTXsCgMWwKLBELsGFjwPA39Te8fe5vnwABxtLHjj96OsiUoiM/cg3w8Ox95a/veJB4yiQEGOeY5tZQ9lmJfR0tKSIUOGMH/+fD744APDXI5LlixBp9MxcOBAsrKyCA8PZ/z48Tg7O7N69WoGDx5MgwYNaNu27V2Podfree655/D29mbfvn2kp6cb3c8s4uTkxPz58/Hz8yMqKorXXnsNJycn3nvvPQYMGEB0dDTr1q1j06ZNgDp5852ys7Pp3r077dq148CBA6SkpDB8+HDGjBlj9I+BLVu24Ovry5YtWzh79iwDBgygRYsWvPbaa3f9PCV9vqKQ3LZtG4WFhYwePZoBAwawdetWAAYNGkTLli2ZNWsWFhYWHD161DB11+jRo8nPz2f79u04ODhw8uRJHB0d77keZSV/ac0tuDsMXqb2go3bCfOfgpeXgaPxxM49mvkyZ6glI34+xI4zqQyes5+5Q9vgYmdlpooLUQkKcuBzP/Mc++8JYO1QpqKvvvoq06ZNY9u2bXTq1AlQL7v269cPFxcXXFxcGDdunKH82LFjWb9+PYsXLy5TUG7atIlTp06xfv16/PzU8/H5558Xu6/44YcfGn6uW7cu48aNY+HChbz33nvY2dnh6OiIpaUlPj4+Jo/122+/kZuby88//4yDg/r5Z8yYQe/evfniiy/w9vYGwM3NjRkzZmBhYUHjxo156qmn2Lx5c7mCcvPmzURFRXH+/HkCAwMB+Pnnn2natCkHDhygTZs2xMfH83//9380btwYUCe/LhIfH0+/fv0IDQ0FoH79+vdch3shl16rg7qPwtA/bo7gEwVzu6uzj9zhsSBPFgyPwNnWkkNx1xn4w16uZOYV358QolI1btyY9u3bM3fuXADOnj3Ljh07GDZsGKBOVvzJJ58QGhpKrVq1cHR0ZP369cTHx5dp/zExMQQGBhpCEqBdu3bFyi1atIgOHTrg4+ODo6MjH374YZmPcfuxwsLCDCEJ0KFDB/R6PbGxsYZlTZs2xcLCwvDe19eXlJSUezrW7ccMDAw0hCRAkyZNcHV1JSYmBoB33nmH4cOH07VrV/7xj39w7tw5Q9k33niDTz/9lA4dOjB58uRydZ66F9KirC58w+DV9fBLX7j2F8zprj536d3EqFh4HTcWvd6OwXP2czIxg/7f72HB8Aj8Xe3MU28hKpKVvdqyM9ex78GwYcMYO3YsM2fOZN68eTRo0IDHH38cgGnTpvGvf/2L6dOnExoaioODA2+99Rb5+fl32WvZ7dmzh0GDBjFlyhS6d++Oi4sLCxcu5Ouvv66wY9yu6LJnEY1Gg16vr5Rjgdpj96WXXmL16tWsXbuWyZMns3DhQp599lmGDx9O9+7dWb16NRs2bGDq1Kl8/fXXjB07tlLqIi3K6sS9Aby6AbyaQFYSzOsB8fuKFQvxdWbJyHb4u9pxPjWbF2bt5tyVrBJ2KEQNo9Golz/N8SrD/cnb9e/fH61Wy2+//cbPP//Mq6++arhfuWvXLvr06cPLL79MWFgY9evX5/Tp02Xed0hICBcvXiQxMdGwbO/evUZldu/eTZ06dfjggw9o3bo1QUFBxMXFGZWxtrZGpyu9819ISAjHjh0jO/vWaGG7du1Cq9XSqFGjMtf5XhR9vosXLxqWnTx5krS0NJo0udU4CA4O5u2332bDhg0899xzzJs3z7AuMDCQkSNHsmzZMt59911+/PHHSqkrSFBWP86+8MoaCIxQB1D/uQ+cKd7brZ6HA0tGtqO+pwMJ6bn0n72H6MvpJexQCFEZHB0dGTBgABMmTCAxMZGhQ4ca1gUFBbFx40Z2795NTEwMr7/+ulGPzrvp2rUrwcHBREZGcuzYMXbs2MEHH3xgVCYoKIj4+HgWLlzIuXPn+Pbbb1m+fLlRmbp163L+/HmOHj1KamoqeXnFb9UMGjQIW1tbIiMjiY6OZsuWLYwdO5bBgwcb7k+Wl06n4+jRo0avmJgYunbtSmhoKIMGDeLw4cPs37+fIUOG8Pjjj9O6dWtu3LjBmDFj2Lp1K3FxcezatYsDBw4YJph+6623WL9+PefPn+fw4cNs2bKlUieflqCsjuzc1MuuDZ+Ewhvw+4twfEmxYn6udix5vR3N/J25mp3PwB/2cuDCtRJ2KISoDMOGDeP69et0797d6H7ihx9+SKtWrejevTudOnXCx8eHvn37lnm/Wq2W5cuXc+PGDdq2bcvw4cP57LPPjMo888wzvP3224wZM4YWLVqwe/duJk6caFSmX79+9OjRg86dO+Pp6VniIyr29vasX7+ea9eu0aZNG55//nmeeOIJZsyYcW8nowRZWVm0bNnS6NW7d280Gg0rV67Ezc2Njh070rVrV+rXr8+iRYsAsLCw4OrVqwwZMoTg4GD69+9Pz549mTJlCqAG8OjRowkJCaFHjx4EBwfz73//+77ra4pGeciGe8nIyMDFxYX09HScnZ3NXZ3S6QpgxSiIuhmSPb+EiNeLFcvILWD4/IPsv3ANG0st014I45kwM/UcFKKMcnNzOX/+PPXq1cPW1tbc1REPqNK+Z2XNA2lRVmcWVvDsD9D2ZjiufQ+2fK4+a3YbZ1srfnq1LV1DvMgr1PPG70f4ekMsehnFRwgh7psEZXWn1ULPL6DzzfsT276A1e+C3vgGvZ21Bd8Pbs3rHdXnib778yyjfztMTn5hVddYCCEeKBKUNYFGA4+/B099DWjg4Bz47/Big6lbaDVM6BXCtOebY22hZW10Ei/M3kNCWvGh8YQQQpSNBGVN0mY4PD8HtFZwYhn8XnwCaIAXWgfy22sRuDtYcyIhg2dm7OJI/HUzVFgIIWo+Ccqaplk/eGmR+nD0uT/hp2cgp3hP19Z1a7FyTAca+ziRmpXHgB/2suLIZTNUWIjSPWT9CUUVq4jvlwRlTdTwCRiySn2M5PJBmNsD0ouHYICbPf8d1Z4nm3iTX6jnrUVH+XLdKenkI6qFopFecnLMNAi6eCgUfb/uHFnoXsjjITVZyin45VnITACXQBi8AjwaFium1ytM2xDLrK3qWIndmnjzzwEtcLCREQyFeSUmJpKWloaXlxf29vaGkW2EuF+KopCTk0NKSgqurq74+voWK1PWPDB7UM6cOZNp06aRlJREWFgY3333Xamj66elpfHBBx+wbNkyrl27Rp06dZg+fTq9evUq0/EeqKAESItXw/LqWbB3h5f/C34tSyy6/Mglxv83ivxCPY19nPhPZGsC3KpmolghSqIoCklJSaSlpZm7KuIB5erqio+PT4n/CKsRQblo0SKGDBnC7NmziYiIYPr06SxZsoTY2Fi8vLyKlc/Pz6dDhw54eXnx97//HX9/f+Li4nB1dSUsLKxMx3zgghIgOxUW9IPEo2DlAM99DyG9Syx6OP46I34+RGpWHh6O1nw/OJzwOrWqtr5C3EGn093XJMBClMTKyspoxpM71YigjIiIoE2bNoahkvR6PYGBgYwdO5b333+/WPnZs2czbdo0Tp06Ve7rzQ9kUALkZsDiwfDXVvV95w+g4/+VONDz5bQbvPbTQU4mZmBtoWXqc6H0Cw+o2voKIYSZVfuRefLz8zl06BBdu3a9VRmtlq5du7Jnz54St1m1ahXt2rVj9OjReHt706xZMz7//PNSR8fPy8sjIyPD6PVAsnWGQUtvjeKz5TNYMrTEx0f8Xe1YOqod3Zt6k6/T8+6SY0xdG4NOOvkIIUQxZgvK1NRUdDpdsdHpvb29SUpKKnGbv/76i6VLl6LT6VizZg0TJ07k66+/5tNPPzV5nKlTpxpmHHdxcTGaKPSBY2EFvb6E3t+qz1qeXKFOAp12sVhRe2tLZg0KZ2wXtfPP99v+4vVfDpKVJyP5CCHE7WrU4yF6vR4vLy9++OEHwsPDGTBgAB988AGzZ882uc2ECRNIT083vG6f/+yBFR4Jkf8Dew9IioIfOkFc8Va6Vqvh3W6N+NeLLbC21LIpJoV+/97NxWvSXV8IIYqYLSg9PDywsLAoNkdbcnIyPj4+JW7j6+tLcHCw0c3ZkJAQkpKSTM4cbmNjg7Ozs9HroVCnHYzYCj6hkJMKP/WGwz+XWLRPC38Wv94OTycbYpMz6TNzl0zXJYQQN5ktKK2trQkPD2fz5s2GZXq9ns2bN9OuXbsSt+nQoQNnz55Fr9cblp0+fRpfX1+sra0rvc41jmsgvLoemvQBfQGsGgtrx4Ou+OXVFoGurBrTgWb+zlzLzuelH/fyy54LMmqKEOKhZ9ZLr++88w4//vgjP/30EzExMYwaNYrs7GxeeeUVAIYMGcKECRMM5UeNGsW1a9d48803OX36NKtXr+bzzz9n9OjR5voI1Z+1A7zw063ZR/bNhl/7lTjsna+LHUteb89Tob4U6BQmrjzBqAWHSc+RbvtCiIeXWYdmGTBgAFeuXGHSpEkkJSXRokUL1q1bZ+jgEx8fj1Z7K8sDAwNZv349b7/9Ns2bN8ff358333yT8ePHm+sj1AxFs494hcCy19VHSH7sAgMXgldjo6J21hbMeKklLXe68sW6U6w7kUTU5XS+HdiS8Dpu5qm/EEKYkdlH5qlqD+xzlGWVFA2/D4T0eLB2gn7/gUY9Six6/FIaY38/QtzVHCy0Gt7tFszIjg3QamWYMSFEzVftn6MUZuLTDEZsgTodID8Tfn8Rdv4TSvj3UvMAV/4Y+yi9w/zQ6RW+XBdL5Lz9XMnMM0PFhRDCPCQoH0YOHuoA6uGvAAps+giWvQYFxSd4drK14tsXW/Blv+bYWmnZcSaVnv/awY4zV6q61kIIYRYSlA8rS2voPR2e+ho0FhC1BOb1hIyEYkU1Gg392wTyvzGP0shbnd9yyNz9fLHuFAU6ffF9CyHEA0SC8mHXZjgMWaHObZlwRB2c4NLBEosGeTuxckwHBkXURlFg1tZzDPh+D5euywAFQogHlwSlgHod4bUt4NUEspJhXi84+nuJRW2tLPjs2VBmvtQKJxtLDsen0etfO1gXnVjFlRZCiKohQSlUterBsA3QqBfo8mDFSFg9DgpySyz+VHNf1rz5GGGBrmTkFjJywWEmrogmt8D0APVCCFETSVCKW2ycYMCv6vRcAAd+VJ+3vBJbYvHAWvYsHdmO1x+vD8Ave+PoO3MXZ1OyqqrGQghR6SQohTGtFrp8qE7ZZe8BKSfg+8fh0E8lPkJiZaFlQs8Q5r/SBncHa04lZdL7u50sOXhRhr8TQjwQJChFyYKehFG7oX5nKLwB/3sDlr4CN9JKLN6pkRdr33yM9g3cuVGg4/+WHuftRUdl2i4hRI0nQSlMc/KGl5dB1ymgtYQTy2H2Y3Bxf4nFvZxt+WVYBOO6BaPVwIqjCTz97Q6iL6dXccWFEKLiSFCK0mm18Ohb6iwkrnXUoe/m9oDtX4G+eMcdC62GMV2CWPR6O3xdbLlwNYe+M3cxfdNp8gvlmUshRM0jQSnKJqA1jNwBzZ4HRQd/fgI/94GMkh8LaVO3FmvffIzuTb0p1CtM33SGPjN3cSJBWpdCiJpFglKUna2LOoh6n3+DlT1c2AGz2kPsuhKLu9pbM/vlcP71Ygvc7K2IScygz4xdfLNRWpdCiJpDZg8R5ZN6Ru3ckxSlvo8YCU9+DJY2JRa/kpnHxBXRrDuRBEBjHyemPR9GaIBLVdVYCCGMlDUPJChF+RXmwcbJsG+W+t4nFJ6fBx5BJRZXFIXVUYlMWnmCa9n5WGg1jHy8Pm88EYSNpUUVVlwIISQoTZKgrASx62Dl3yDnqnpJttc0aDFInTC6BFez8pi06gSrj6v3N4O9HZn2fBhhga5VWGkhxMNOgtIECcpKkpGoTtV1YYf6vtnz8PQ36n1NE9ZGJTJxZTSpWfloNTCiYwPe6hqErZW0LoUQlU8mbhZVy9kXhqyELhPVabuil6rPXJqYiQSgZ6gvG95+nGfC/NArMHvbOZ76dgeH469XYcWFEKJ00qIUFe/iflg6TH3mUmsJnT+ADm+C1nRLcf2JJD5YHk1qVh5aDQx/rD7vPBksrUshRKWRS68mSFBWkRtp8Mdb6mg+AP7h0GcmeIWY3CQtJ58p/zvJ8iOXAajv4cC0F5oTXqdW5ddXCPHQkaA0QYKyCikKHP0V1v0d8tJBawWPj1dH+rGwMrnZppPJ/H15FCmZeWg08GqHeozr1gg7a2ldCiEqTqUG5cWLF9FoNAQEBACwf/9+fvvtN5o0acKIESPKX+sqIEFpBhkJ8MfbcPrmwATeodB3JviGmdwkPaeAT1afZOmhSwDUdbfny+fDaFtPWpdCiIpRqZ15XnrpJbZs2QJAUlISTz75JPv37+eDDz7g448/Ll+NxYPL2Q8GLoTn/gN2bpAcBT90hs2fqM9ilsDF3oqvXghj3tA2+DirY8YO+GEPf18exfXs/Cr+AEKIh1m5gjI6Opq2bdsCsHjxYpo1a8bu3bv59ddfmT9/fkXWTzwoNBpo/gKM3g9N+qrjxe746uZsJAdMbta5sRfr3+5I/9YBKAr8ti+ezl9v5dd9cej0D9VdAyGEmZQrKAsKCrCxUYcq27RpE8888wwAjRs3JjGx5EGyhQDA0Qv6/wT9fwYHL0iNhTlPwvoPID+nxE1c7Kz48vkwFo54hEbeTqTlFPDB8mj6zNzJoTh5lEQIUbnKFZRNmzZl9uzZ7Nixg40bN9KjRw8AEhIScHd3r9AKigdUkz4weh+EDQQU2DNDHWD9wk6TmzxS353VbzzK5N5NcLK1JPpyBv1m7WbckmNcySz5Eq4QQtyvcnXm2bp1K88++ywZGRlERkYyd+5cAP7+979z6tQpli1bVuEVrSjSmacaOr1BfZQkQ30shDbDoetHYONkcpPUrDy+WHuKJTc7+zjZWPL2k8EMaVcHSwsZR0MIcXeV/niITqcjIyMDNzc3w7ILFy5gb2+Pl5dXeXZZJSQoq6ncdNg4CQ7NV9+7BELvf0HDJ0rd7HD8dSavPEHUZXWey0beTnz0TFPaNZArG0KI0lVqUN64cQNFUbC3twcgLi6O5cuXExISQvfu3ctf6yogQVnN/bUVVr0BaXHq+5YvQ7fPwM7V5CY6vcKiAxeZtv4U13MKAOgd5sffezXG18Wu8usshKiRKjUou3XrxnPPPcfIkSNJS0ujcePGWFlZkZqayjfffMOoUaPuq/KVSYKyBsjLgj8/gX3fAwo4+sDT/4TGvUrdLC0nn683nObXfXHoFbC3tmBslyBefbSuTOMlhCimUp+jPHz4MI899hgAS5cuxdvbm7i4OH7++We+/fbb8tVYiCI2jtDzC3h1Hbg3hKwkWDhQHT82O9XkZq721nzStxmrxjxKeB03cvJ1fLHuFD2n72Db6StV+AGEEA+ScgVlTk4OTk5qR4sNGzbw3HPPodVqeeSRR4iLi6vQCoqHWO1HYORO6PAWaLTqjCTftoK9s0FXaHKzZv4uLB3Zjm/6h+HhaMNfqdlEzt3PiJ8PcvFayY+gCCGEKeUKyoYNG7JixQouXrzI+vXr6datGwApKSlyOVNULCs7eHIKDN8EPs3VMWPXjYfZj8Jf20xuptFoeK5VAFvGPc7wR+thodWw4WQyXb/ZxvRNp8kt0FXhhxBC1GTluke5dOlSXnrpJXQ6HV26dGHjxo0ATJ06le3bt7N27doKr2hFkXuUNZheB4d/hs0fw41r6rImfaDbp+Bau9RNTydn8tGqE+w+dxUAf1c73nkymL4t/bHQaiq75kKIaqjSHw9JSkoiMTGRsLAwtFq1Ybp//36cnZ1p3Lhx+WpdBSQoHwA512DrVDjwH1D0YGkHj74NHd5QW6AmKIrCmqgkPl19ksT0XACCvR15t1sjujXxRqORwBTiYVJl02xduqQ+8F00k0h1J0H5AEmKhrXjIe7maD4utaH7ZxDSWx1b1oQb+Tp+2nOBWVvPkX5DfZykRaAr7/VoRPsGHlVRcyFENVCpvV71ej0ff/wxLi4u1KlThzp16uDq6sonn3yCXq8vd6WFuCc+zWDoH/D8PHD2h/R4WDwYfu4DKTEmN7OztmDk4w3Y/l5nRndugJ2VBUcvpvHSj/sYPGcfxy+lVd1nEEJUe+VqUU6YMIE5c+YwZcoUOnToAMDOnTv56KOPeO211/jss88qvKIVRVqUD6j8bNj5T9j1LejyQGMBEa+rE0WXMlgBQEpmLjP/PMtv++Mp0Km/Dr1CfXjnyUY09HKsgsoLIcyhUi+9+vn5MXv2bMOsIUVWrlzJ3/72Ny5fvnzvNa4iEpQPuGvnYcOHcOoP9b29B3SdDC1eBm3pF1AuXsvhnxtPs/zoZRQFtBp4PjyAN7sG4+8qI/wI8aCp1KC0tbXl+PHjBAcHGy2PjY2lRYsW3Lhx495rXEUkKB8SZzer9y+vnlHf+7WEntMgsM1dN41NyuSrDbFsPJkMgLWFlsHt6vC3Tg1wd7SpzFoLIapQpd6jDAsLY8aMGcWWz5gxg+bNm5dnl0JUrIZPwKjd6jix1k6QcATmdIXloyAzudRNG/k48eOQ1vx3VHseqV+LfJ2eOTvP0/HLLfxz42kycwuq6EMIIaqDcrUot23bxlNPPUXt2rVp164dAHv27OHixYusWbPGMLxddSQtyodQZjJsngJHf1XfWzvB4/8HbV8HK9tSN1UUhR1nUvly/SmiL2cAUMvBmr91asDLj9TB1krGkBWipqr0x0MSEhKYOXMmp06dAiAkJIQRI0bw6aef8sMPP5Sv1lVAgvIhdukgrPk/SDisvnf2Vzv7tBgEFpalbqrXK6yNTuLrDbH8lZoNgJ+LLW92DaJfqwCZA1OIGqjKnqO83bFjx2jVqhU6XfUdHkyC8iGn18Ox32DL57cminZvCJ0/gCZ979rhp1Cn57+HLzF90xnDoAW1a9nz+uP16dcqQFqYQtQgEpQmSFAKAApy4eAc2PE15KjD2uHTHJ6YBA27ljpgAUBugY4Fe+P499ZzXMvOB8DTyYbhj9Zj0CN1cLQpvYUqhDA/CUoTJCiFkdwM2Ptv2D0D8jPVZbXbq4+U1H7krpvn5Bey6MBFftj+l6GF6WxrydD2dRnaoR61HKwrs/ZCiPtQqb1eK9rMmTOpW7cutra2REREsH//fpNl58+fj0ajMXrZ2pbeIUMIk2ydodP78OYxaDcGLGwgfjfM7Q6/vgCJx0vd3N7aklc61GPb/3Xmy+ebU9/TgYzcQr798ywd/vEnU/53goS06vu4lBDi7u6pRfncc8+Vuj4tLY1t27bdU4ty0aJFDBkyhNmzZxMREcH06dNZsmQJsbGxeHl5FSs/f/583nzzTWJjY299CI0Gb2/vMh1PWpSiVOmXYdsXcGQBKDe/x836qfcw3RvcdXOdXmHDiSRmbj1r6CVrZaHh2Zb+jHy8AfU9ZaQfIaqLSrn0+sorr5Sp3Lx588q6SyIiImjTpo3huUy9Xk9gYCBjx47l/fffL1Z+/vz5vPXWW6SlpZX5GLeToBRlknoWtn4O0f9V32ssoNVg6PgeuPjfdfOix0r+vfUse/9SpwTTaKBnMx/+1qkhzfxdKrP2QogyMMs9ynuVn5+Pvb09S5cupW/fvoblkZGRpKWlsXLlymLbzJ8/n+HDh+Pv749er6dVq1Z8/vnnNG3atMRj5OXlkZeXZ3ifkZFBYGCgBKUom8Tj8OcncGaD+t7CBtq+Bo++Aw7uZdrFobjrzNp6lk0xKYZlHYM9+VunBkTUqyXTewlhJjXiHmVqaio6na7YZVNvb2+SkpJK3KZRo0bMnTuXlStXsmDBAvR6Pe3btzdM93WnqVOn4uLiYngFBgZW+OcQDzDf5jBoCbyyFmq3Uwdc3zMD/hUGW7+AvMy77iK8jhv/iWzDurceo28LPyy0GrafvsKLP+yl36zdbI5Jxoz/XhVC3IVZW5QJCQn4+/uze/duwwg/AO+99x7btm1j3759d91HQUEBISEhDBw4kE8++aTYemlRigqjKHBmI2z+GJKj1GX27tDhTWj9Ktg4lWk38Vdz+H77OZYcukR+oTotXWMfJ0Z1akCvUF+sZPACIapEjWhRenh4YGFhQXKy8dibycnJ+Pj4lGkfVlZWtGzZkrNnz5a43sbGBmdnZ6OXEOWi0UBwN3h9Ozw/F2o1UJ/B3DgJ/tkMtv4Dcq7ddTe13e357NlQdr7Xmdcfr4+jjSWnkjJ5c+FRHvtiCzO3nOX6zWczhRDmZ9agtLa2Jjw8nM2bNxuW6fV6Nm/ebNTCLI1OpyMqKgpfX9/KqqYQxrRatSfs6H3QZ6YamLlpsHUqTA9VgzMr5a678XK2ZULPEHaN78K4bsF4ONqQlJHLtPWxPDJ1M+//9zixSXe/tCuEqFxmvfQK6uMhkZGRfP/997Rt25bp06ezePFiTp06hbe3N0OGDMHf35+pU6cC8PHHH/PII4/QsGFD0tLSmDZtGitWrODQoUM0adLkrseTXq+iwul1cHIF7PgGkqPVZZa20GoItH8DXMt2XzyvUMfq44nM23WBqMvphuUdGrrzSvt6dGnshVYrHX+EqChlzQOzj7M1YMAArly5wqRJk0hKSqJFixasW7fO0MEnPj4e7W3jb16/fp3XXnuNpKQk3NzcCA8PZ/fu3WUKSSEqhdZCbWE2fQ5Or4PtX8Hlg7D/Bzg4F8JeVHvJ3uU5TBtLC55rFcCzLf05FHedubvOsy46iV1nr7Lr7FXquNsztH1dXmgdKEPkCVGFzN6irGrSohSVTlHg/DY1MC/sUJdptND0WXjsXfAu+VGmkly6nsMve+L4fX88GbmFADjaWNK/dSBD29eltrt9ZXwCIR4KNeI5SnOQoBRV6uJ+NTDPrL+1rFEveGwcBISXeTc5+YUsO3yZebvOc+6KOs2XRgNPNPbm1Q51adfAXZ7HFOIeSVCaIEEpzCLxuDpTycmVwM1fufqd1MCs++hdZyspotcr7Dibyrxd59kae8WwvLGPE690qEufFv4y1ZcQZSRBaYIEpTCr1DOw859wfBHo1UupBEaogRn0ZJkDE+DclSzm77rA0kOXuFGgjktby8Gal9rWZtAjtfF1sauMTyDEA0OC0gQJSlEtXI+D3d/C4V/U0X4AfELhkb+pnYKsyj4jTvqNAhYfuMj83Re4fHOmEq0GHgvyZECbQJ4I8cLGUlqZQtxJgtIECUpRrWQmqUPiHZgLBeq9R+w9oPUr0HoYOJf9+eBCnZ5NMcnM333BMBA7gJu9FX1b+jOgTSCNfeQ7L0QRCUoTJChFtZRzDQ7/BPv/Axk3xy3WWkKTvhAxEgJa39Nl2Qup2Sw9dImlhy6RlJFrWN48wIX+rQPpHeaHi51VBX8IIWoWCUoTJChFtaYrhFN/wL7v1Qmki/i1UgOzaV+wtCn77vQK289cYfGBi2yKSaZAp/6621hq6dnMh/5tAnmknrsMZCAeShKUJkhQihoj8Rjs+wGilty6j+ngBW2GQfgr4FS2ycqLXM3KY8XRBBYfuEhs8q2h8WrXsueF8AD6hQfg5yodgMTDQ4LSBAlKUeNkp8KheXBgDmQmqsu0VtDsOYh4HfzL/jwmqJNKH7+UzqKDF/nf0QQy89Tet5qiDkCtA+naRDoAiQefBKUJEpSixtIVQMwq9bLsxdumoAtoo16WDXkGLK3vaZc38nWsO5HIogMXjToAudpb0beFP/1bB9LET35PxINJgtIECUrxQLh8WB1LNvq/oLs5JZejz83LskPB0euedxl3NZslB4t3AGrs48QzLfx4JsyPADcZMk88OCQoTZCgFA+UrBQ4OA8OzoGsm/O6WlirvWXDI6FOh3vqLQtqB6AdZ66w+OBFNp1MIV+nN6xrU9eNPi38eSrUFzeHe2u9ClHdSFCaIEEpHkiF+erwePtmqzOXFHEPUqf7avESOHjc827TcwpYG53IyqMJ7D1/laK/FpZaDY8He9KnpT9PhnhjZy33M0XNI0FpggSleOBdPgSHfoKopbcGMdBaQcjT0CoS6j2uTj59jxLTb/C/YwmsPJrAiYQMw3J7awu6N/WhTws/Hm3ogaWFWeeDF6LMJChNkKAUD428TPUe5qH5kHDk1nK3ujdbmS/f8yMmRc6mZLLiSAIrj13m4rUbhuXuDtY83dyXPi39aRnoKjOaiGpNgtIECUrxUEo8ro78c3wx5N1sDWotIbiH2vmnQRd1Aup7pCgKh+PTWHX0Mn8cT+Rqdr5hXe1a9vRp4UefFv409HKsoA8iRMWRoDRBglI81PKz4cQKNTRvf8TEJRBaDoaWL4OLf7l2XaDTs/NsKquOJrD+RBI5+TrDuqZ+zjwT5kfPZr4y2bSoNiQoTZCgFOKmlBj1Xuax3yE3TV2m0UJQN/VeZlA3sLAs165z8gvZeDKZVUcT2Hb6CoX6W39mmvo50yvUl57NfKjvKS1NYT4SlCZIUApxh4JcdSCDQz9B3M5by518ocUgCHsRPILKvftr2fmsiUpkbXQie85d5bbMpJG3Ez1DfegV6kuQl6Pc0xRVSoLSBAlKIUqReka9LHv0N8i5emu5X0toPgCa9SvXYAZFrmblsfFkMmujk9h1NtWopdnA04GezXzpGepDE19nCU1R6SQoTZCgFKIMCvPVWUyO/Q5nN4Ny836jRgv1O0Pz/tD4abAp/6XT9JwCNsYkszYqkR1nUo0GNqjjbk+PZj70auZL8wAXCU1RKSQoTZCgFOIeZV2BE8vh+CLjwQys7KFRL7Wl2aAzWJR/fsvM3AL+PJXCmqhEtsZeIa/wVmj6u9rRs5kPPUN9aBnoJlOCiQojQWmCBKUQ9+HqOXXar+OL4dq5W8vt3dXLsqH973mS6Ttl5xWyNfYKa6IT2XIqxaj3rLezDT2a+tAlxJuIerWwtZIRgUT5SVCaIEEpRAVQFHVg9qjF6ghAOam31rnVUy/NhvYHj4b3dZjcAh3bTl9hbVQim2JSyLo5JRiAnZUF7Ru406mxF52CPQmsJY+diHsjQWmCBKUQFUxXCH9tVS/NnvoDCnJurfNrdbMT0HP31QkIIK9Qx84zqWw4kczW0ykkZ+QZrW/o5UjnRp50buRF67q1sLaUofRE6SQoTZCgFKIS5WVB7Br10uy5P2/rBGQB9R5T58xs/HS5h84roigKMYmZbD2dwtZTVzgUfx3dbT1oHawt6NDQg86NvejUyBNfF7v7Op54MElQmiBBKUQVyUqB6GXq5dnLh25boYHACAjprb7c6tz3odJzCthx9gpbY9VXapZxa7OxjxOdGnnRuZEnreq4YSUDtwskKE2SoBTCDK6eUwc1iPnfHaEJ+IbdDM0+4Bl834fS6xVOJGSwJTaFrbEpHLmYxu1/5ZxsLekY5EmnRp48HuyJl7PtfR9T1EwSlCZIUAphZumX4NRqNTTjdoFy61EQPBrdamn6ht1X79ki17Lz2XHmCltOpbDt9BWu5xQYrW/s48TjwWpohtd1w8ZSetI+LCQoTZCgFKIaybqi3tOM+Z/aIUh/W4i51lbvaYb0hoC25ZpD8046vcLxS2lsib3C1tgUoi6nG7U27awsaNfAnY5BHnQM9qSeh4MMdvAAk6A0QYJSiGoqNx1Or1cv0Z7ZBIW35rnE0RsaP6UGZ91H72twg9tdzcpj59lUtp2+wo4zqVzJNL63GeBmR8dgTzoGedK+oTvOthVzXFE9SFCaIEEpRA2QnwPnNqstzdh1kJd+a52tKwR3h0Y9ocETYFsxv8dFPWm3n7nC9tNXOHjhutGwehZaDa1qu9IxyJOOwZ6E+rvIKEE1nASlCRKUQtQwhflwfrva0jy12nhwA62V+thJo17qJNSugRV22Jz8Qvb+dZXtp9UW5/nUbKP1bvZWPBrkabhM6y2dgmocCUoTJCiFqMH0OnXC6di16r3Nq2eN1/uEqqHZqCf4tqiQzkBFLl7LYdtptbW5+9xVo1GCAOp7ONC2Xi3DK8BNRgqq7iQoTZCgFOIBknpGDczYtWqA3t6D1slPDcxGvdRWp6VNhR22QKfnSHwa209fYfuZK8U6BQH4udjStl4t2tSrRUS9WjTwlPk2qxsJShMkKIV4QGWnwpkNanCe/RMKbrtUau0IDbqooRnUDRzcK/TQaTn5HLxwnf0XrrH//DWiLqcbjRQE4O5gTeu6brSt505EvVqE+DpjIfc4zUqC0gQJSiEeAgW5cGHHrdZmZuKtdRotBD6itjaDu4NHcIVeogV1BpQj8Wk3g/MqR+LTjKYOA3C0sSS8jpvhUm3zABd5hrOKSVCaIEEpxENGUSDx6K37mklRxuud/dX5NBt0gXqdKry1CeqA7tGX09l3/hoHzl/j4IXrZN5xj9PaUkvLQFfa1qtF67q1aFXbFSd5HKVSSVCaIEEpxEMu7SKcXqeG5oVdoLv92UmNOiJQgy7qK7Bthd7bLKLTK8QkZnDg5qXaAxeukZqVb1RGq4HGPs60qetG67q1aF3XTQZ3r2ASlCZIUAohDApuQNxudaaTc1sg5YTxeit7dYCDouCshMu0oD7D+VdqtiE0D164Tvy1nGLl/F3tDMHZpm4tgrwc5VnO+yBBaYIEpRDCpMwkdSi9ouDMTjFe7+R3MzQ7Q/3OlXKZtkhyRi4HL1xXgzPuGicTMrijfxDOtpaG1maburUI9XfB1kruc5aVBKUJEpRCiDJRFEg+cTM0/1RbnsUu0zZXg7N+Z3XqMKvKG3QgK6+Qo/FphuA8HJfGjQKdURlrCy3NA1zU8KzjRovarng4Vvyl4weFBKUJEpRCiHIpuAHxe261NpOjjddb2qr3NOt1hHqPg1/LChuTtsTq6PQ373Ne5+CFaxy4cL3YPJygXq5tHuBCaIALYQGuhAa4yJi1N0lQmiBBKYSoEJnJty7T/rUFspKN11s7Qu12N4OzozpqkLbyLosqikLc1RzDPc6Dcdf4KzW72EAIoI4i1DzAheYBrjQPcKGpnwt21g/fJVsJShMkKIUQFU5R1FGCzm9Tx6W9sANuXDcuY+uqdgwqCk7PxpXSMeh2mbkFRF/O4PilNI5fSufYpTQuXb9RrJyFVkOQlyNhAa40D3Shub8rjXycsLa8/6nNqjMJShMkKIUQlU6vV3vQnt9+Mzh3QX6mcRkHT6j72K3grFW/0oMT1Imsi4Lz+KU0jl1KLza9GKjPdYb4OhMW4EIzfxea+jkT5PVghWeNCsqZM2cybdo0kpKSCAsL47vvvqNt27Z33W7hwoUMHDiQPn36sGLFijIdS4JSCFHldIWQeOxWizN+r/F8mwDOAeqYtHUfVUcOcm9QJcGpKArJGXkcu5R2W4Cmk36joFhZKwsNDb2caOrnTBNfZ5r4ORPi64yLXc2851ljgnLRokUMGTKE2bNnExERwfTp01myZAmxsbF4eXmZ3O7ChQs8+uij1K9fn1q1aklQCiFqjsI8uHzoVovz4n7Q3xFM9h5qT9raEep//VpWyuAHJVEUhfhrORy7lM7xi2mcSMjgREI6GbmFJZYPcLOjia8zTf1caOKnBqifi221HwS+xgRlREQEbdq0YcaMGQDo9XoCAwMZO3Ys77//fonb6HQ6OnbsyKuvvsqOHTtIS0uToBRC1Fz5OersJ+e3qz1rLx++41EUwMJaDcvACKj9iPpfB48qq6KiKFxOu8HJhAxOJmZwIiGDkwkZXE4rfs8TwMXO6mZ4OhvCs4GnI1YW1efSbY0Iyvz8fOzt7Vm6dCl9+/Y1LI+MjCQtLY2VK1eWuN3kyZM5fvw4y5cvZ+jQoaUGZV5eHnl5t75wGRkZBAYGSlAKIaqvwjz1Um38XjVA4/caT1hdpFaDW6FZ+xFwDwJt1QZRek4BJxOLwjOdkwkZnE3JovDO0RFQn/Ns7OtEUz8Xmvk708zPhUY+TmYbJKGsQWlZhXUqJjU1FZ1Oh7e3t9Fyb29vTp06VeI2O3fuZM6cORw9erRMx5g6dSpTpky536oKIUTVsbRRn8kMvNlXQ1Hg2l+3QvPiPrhyCq6dU19Hf1XL2bmpoRnYVr3P6dcSrCt3AmkXeyvaNXCnXYNboxTlFeo4k5ylBujNlufJxAyy8goN90ANH1WrIcjbiWZ+zjTzVzsOhfg6YW9t1ngyUn1qUgaZmZkMHjyYH3/8EQ+Psl1ymDBhAu+8847hfVGLUgghagyNRu3c494AWrykLsu5BpcO3AzO/eo9zxvX1QHfT6+7uZ0F+DSDgDbg31r9bxV0ErKxtDCEXhG9XuHi9RyiL2cQnZBO9GX1dT2ngJjEDGISM1hy6BKgDgjfwNPR0Ns21F+992mu2VRq1KXXo0eP0rJlSywsbjXT9Xp1jjetVktsbCwNGjQo9Zhyj1II8UAqzFenELu491ar885BEEBtdfq3hoCbL/9wdZkZKIpCYnouUZfTOXE5neiEDKIvp5NSwuMqAPU8HAzB2czfhbBAVxxtyt/eqxH3KEHtzNO2bVu+++47QA2+2rVrM2bMmGKdeXJzczl79qzRsg8//JDMzEz+9a9/ERwcjLW1danHk6AUQjwUFAXSL8Hlg3DpoNr6TDhavJMQqLOiBLRRQzOgDXg1AQvzXXBMyci92epUg/OEiU5Dvwxry2NBnuU+To24RwnwzjvvEBkZSevWrWnbti3Tp08nOzubV155BYAhQ4bg7+/P1KlTsbW1pVmzZkbbu7q6AhRbLoQQDzWNBlwD1VfTZ9VlhfnqGLVFwXnpAFw/D6mn1VfRvU4re/BrBQHhty7bOvtWWdW9nG3p4mxLl8a3+q9czcrjRIJ62fbE5QyiLqfT1M+llL1UHLMH5YABA7hy5QqTJk0iKSmJFi1asG7dOkMHn/j4eLRV3ItLCCEeSJbW4N9KfUWMUJdlp6r3N4uC8/JhyMuAuJ3qq4ijj9o5yPBqAY6mn3WvaO6ONnQM9qRjcPlbkOVl9kuvVU0uvQohRCn0erV1eemAetn24gG4EgOKvnhZ5wA1MIuC07dlpc7RWdFqzD3KqiZBKYQQ9yg/G5KiIeHIrVfqaaCE+HCtbdzy9G0Bdq5VXOGykaA0QYJSCCEqQF4mJB43Ds9r50ouW6v+reD0CQXvZlU6qpApEpQmSFAKIUQluZGmjih0e3imxZVc1tEbvJvefDVT/+sRXGXj2YIEpUkSlEIIUYVyrkHi0VvBmXwCrp2nxMu2Wks1LO8MUCffShkkQYLSBAlKIYQws7wsdQi+5Gg1OJNPqD/nppdc3s7tVmgWvTxD7nt4PglKEyQohRCiGlIUyLh8KzSLAjT1DCi6EjbQwOBl0KBLuQ9ZYwYcEEIIIdBowCVAfQV3v7W8IBdSY41bnknR6mwqtUofsrSiSFAKIYSovqxswTdMfd0uKwUcqmbwAQlKIYQQNU8VjgokY8MJIYQQpZCgFEIIIUohQSmEEEKUQoJSCCGEKIUEpRBCCFGKh67Xa9H4ChkZGWauiRBCCHMqyoG7jbvz0AVlZmYmAIGBgWauiRBCiOogMzMTFxcXk+sfuiHs9Ho9CQkJODk5obmPQXYzMjIIDAzk4sWLNWoovJpab6i5dZd6V72aWnepd9VSFIXMzEz8/PzQak3fiXzoWpRarZaAgIAK25+zs3ON+mIUqan1hppbd6l31aupdZd6V53SWpJFpDOPEEIIUQoJSiGEEKIUEpTlZGNjw+TJk7GxqbrZuCtCTa031Ny6S72rXk2tu9S7enroOvMIIYQQ90JalEIIIUQpJCiFEEKIUkhQCiGEEKWQoBRCCCFKIUFZipkzZ1K3bl1sbW2JiIhg//79pZZfsmQJjRs3xtbWltDQUNasWVNFNVVNnTqVNm3a4OTkhJeXF3379iU2NrbUbebPn49GozF62draVlGNb/noo4+K1aNx48albmPu8w1Qt27dYvXWaDSMHj26xPLmOt/bt2+nd+/e+Pn5odFoWLFihdF6RVGYNGkSvr6+2NnZ0bVrV86cOXPX/d7r70hF172goIDx48cTGhqKg4MDfn5+DBkyhISEhFL3WZ7vW0XWG2Do0KHF6tCjR4+77tfc5xwo8Tuv0WiYNm2ayX1WxTmvLBKUJixatIh33nmHyZMnc/jwYcLCwujevTspKSkllt+9ezcDBw5k2LBhHDlyhL59+9K3b1+io6OrrM7btm1j9OjR7N27l40bN1JQUEC3bt3Izs4udTtnZ2cSExMNr7i4uCqqsbGmTZsa1WPnzp0my1aH8w1w4MABozpv3LgRgBdeeMHkNuY439nZ2YSFhTFz5swS13/55Zd8++23zJ49m3379uHg4ED37t3Jzc01uc97/R2pjLrn5ORw+PBhJk6cyOHDh1m2bBmxsbE888wzd93vvXzfKrreRXr06GFUh99//73UfVaHcw4Y1TkxMZG5c+ei0Wjo169fqfut7HNeaRRRorZt2yqjR482vNfpdIqfn58yderUEsv3799feeqpp4yWRUREKK+//nql1rM0KSkpCqBs27bNZJl58+YpLi4uVVcpEyZPnqyEhYWVuXx1PN+Koihvvvmm0qBBA0Wv15e4vjqcb0BZvny54b1er1d8fHyUadOmGZalpaUpNjY2yu+//25yP/f6O1IR7qx7Sfbv368ASlxcnMky9/p9u18l1TsyMlLp06fPPe2nup7zPn36KF26dCm1TFWf84okLcoS5Ofnc+jQIbp27WpYptVq6dq1K3v27Clxmz179hiVB+jevbvJ8lUhPT0dgFq1apVaLisrizp16hAYGEifPn04ceJEVVSvmDNnzuDn50f9+vUZNGgQ8fHxJstWx/Odn5/PggULePXVV0sdcL+6nO8i58+fJykpyeh8uri4EBERYfJ8lud3pKqkp6ej0WhwdXUttdy9fN8qy9atW/Hy8qJRo0aMGjWKq1evmixbXc95cnIyq1evZtiwYXctWx3OeXlIUJYgNTUVnU6Ht7e30XJvb2+SkpJK3CYpKemeylc2vV7PW2+9RYcOHWjWrJnJco0aNWLu3LmsXLmSBQsWoNfrad++PZcuXarC2kJERATz589n3bp1zJo1i/Pnz/PYY48ZpkW7U3U73wArVqwgLS2NoUOHmixTXc737YrO2b2cz/L8jlSF3Nxcxo8fz8CBA0sdnPtev2+VoUePHvz8889s3ryZL774gm3bttGzZ090Ol2J5avrOf/pp59wcnLiueeeK7VcdTjn5fXQzR7ysBg9ejTR0dF3vQfQrl072rVrZ3jfvn17QkJC+P777/nkk08qu5oGPXv2NPzcvHlzIiIiqFOnDosXLy7Tv1Srgzlz5tCzZ0/8/PxMlqku5/tBVFBQQP/+/VEUhVmzZpVatjp831588UXDz6GhoTRv3pwGDRqwdetWnnjiiSqpQ0WYO3cugwYNumuntOpwzstLWpQl8PDwwMLCguTkZKPlycnJ+Pj4lLiNj4/PPZWvTGPGjOGPP/5gy5Yt9zylmJWVFS1btuTs2bOVVLuycXV1JTg42GQ9qtP5BoiLi2PTpk0MHz78nrarDue76Jzdy/ksz+9IZSoKybi4ODZu3HjPUz3d7ftWFerXr4+Hh4fJOlS3cw6wY8cOYmNj7/l7D9XjnJeVBGUJrK2tCQ8PZ/PmzYZler2ezZs3G7UGbteuXTuj8gAbN240Wb4yKIrCmDFjWL58OX/++Sf16tW7533odDqioqLw9fWthBqWXVZWFufOnTNZj+pwvm83b948vLy8eOqpp+5pu+pwvuvVq4ePj4/R+czIyGDfvn0mz2d5fkcqS1FInjlzhk2bNuHu7n7P+7jb960qXLp0iatXr5qsQ3U650XmzJlDeHg4YWFh97xtdTjnZWbu3kTV1cKFCxUbGxtl/vz5ysmTJ5URI0Yorq6uSlJSkqIoijJ48GDl/fffN5TftWuXYmlpqXz11VdKTEyMMnnyZMXKykqJioqqsjqPGjVKcXFxUbZu3aokJiYaXjk5OYYyd9Z7ypQpyvr165Vz584phw4dUl588UXF1tZWOXHiRJXVW1EU5d1331W2bt2qnD9/Xtm1a5fStWtXxcPDQ0lJSSmx3tXhfBfR6XRK7dq1lfHjxxdbV13Od2ZmpnLkyBHlyJEjCqB88803ypEjRww9Q//xj38orq6uysqVK5Xjx48rffr0UerVq6fcuHHDsI8uXboo3333neH93X5HqqLu+fn5yjPPPKMEBAQoR48eNfre5+Xlmaz73b5vlV3vzMxMZdy4ccqePXuU8+fPK5s2bVJatWqlBAUFKbm5uSbrXR3OeZH09HTF3t5emTVrVon7MMc5rywSlKX47rvvlNq1ayvW1tZK27Ztlb179xrWPf7440pkZKRR+cWLFyvBwcGKtbW10rRpU2X16tVVWl+gxNe8efNM1vutt94yfEZvb2+lV69eyuHDh6u03oqiKAMGDFB8fX0Va2trxd/fXxkwYIBy9uxZk/VWFPOf7yLr169XACU2NrbYuupyvrds2VLid6Oobnq9Xpk4caLi7e2t2NjYKE888USxz1OnTh1l8uTJRstK+x2pirqfP3/e5Pd+y5YtJut+t+9bZdc7JydH6datm+Lp6alYWVkpderUUV577bVigVcdz3mR77//XrGzs1PS0tJK3Ic5znllkWm2hBBCiFLIPUohhBCiFBKUQgghRCkkKIUQQohSSFAKIYQQpZCgFEIIIUohQSmEEEKUQoJSCCGEKIUEpRCiVCXNcC/Ew0SCUohqbOjQoWg0mmKvHj16mLtqQjw0ZJotIaq5Hj16MG/ePKNlNjY2ZqqNEA8faVEKUc3Z2Njg4+Nj9HJzcwPUy6KzZs2iZ8+e2NnZUb9+fZYuXWq0fVRUFF26dMHOzg53d3dGjBhBVlaWUZm5c+fStGlTbGxs8PX1ZcyYMUbrU1NTefbZZ7G3tycoKIhVq1YZ1l2/fp1Bgwbh6emJnZ0dQUFBxYJdiJpMglKIGm7ixIn069ePY8eOMWjQIF588UViYmIAyM7Opnv37ri5uXHgwAGWLFnCpk2bjIJw1qxZjB49mhEjRhAVFcWqVato2LCh0TGmTJlC//79OX78OL169WLQoEFcu3bNcPyTJ0+ydu1aYmJimDVrFh4eHlV3AoSobOYelV0IYVpkZKRiYWGhODg4GL0+++wzRVHUGWNGjhxptE1ERIQyatQoRVEU5YcfflDc3NyUrKwsw/rVq1crWq3WMFOFn5+f8sEHH5isA6B8+OGHhvdZWVkKoKxdu1ZRFEXp3bu38sorr1TMBxaiGpJ7lEJUc507d2bWrFlGy2rVqmX4+c5Je9u1a8fRo0cBiImJISwsDAcHB8P6Dh06oNfriY2NRaPRkJCQwBNPPFFqHZo3b2742cHBAWdnZ1JSUgAYNWoU/fr14/Dhw3Tr1o2+ffvSvn37cn1WIaojCUohqjkHB4dil0Irip2dXZnKWVlZGb3XaDTo9XoAevbsSVxcHGvWrGHjxo088cQTjB49mq+++qrC6yuEOcg9SiFquL179xZ7HxISAkBISAjHjh0jOzvbsH7Xrl1otVoaNWqEk5MTdevWZfPmzfdVB09PTyIjI1mwYAHTp0/nhx9+uK/9CVGdSItSiGouLy+PpKQko2WWlpaGDjNLliyhdevWPProo/z666/s37+fOXPmADBo0CAmT55MZGQkH330EVeuXGHs2LEMHjwYb29vAD766CNGjhyJl5cXPXv2JDMzk127djF27Ngy1W/SpEmEh4fTtGlT8vLy+OOPPwxBLcSDQIJSiGpu3bp1+Pr6Gi1r1KgRp06dAtQeqQsXLuRvf/sbvr6+/P777zRp0gQAe3t71q9fz5tvvkmbNm2wt7enX79+fPPNN4Z9RUZGkpubyz//+U/GjRuHh4cHzz//fJnrZ21tzYQJE7hw4QJ2dnY89thjLFy4sAI+uRDVg0ZRFMXclRBClI9Go2H58uX07dvX3FUR4oEl9yiFEEKIUkhQCiGEEKWQe5RC1GBy50SIyictSiGEEKIUEpRCCCFEKSQohRBCiFJIUAohhBClkKAUQgghSiFBKYQQQpRCglIIIYQohQSlEEIIUQoJSiGEEKIU/w8t0TqcAxxBoAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x250 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Test Loss: 0.3898, Accuracy: 0.8745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the remaining code, which installs the gradio package and sets up an easy-to-use inter- face with the trained model, that you can type in any sentence and have the model decide if it is subjective or objective. To use the interface, just type in the sentence and click the classify button. You may find that it is better at classifying longer sentences, as that is the nature of the dataset it was trained on."
      ],
      "metadata": {
        "id": "SV4zHHKCD0Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gradio interface\n",
        "def classify_sentence(sentence):\n",
        "    embedding = sentence_to_embedding(sentence, glove)\n",
        "    embedding = embedding.unsqueeze(0)\n",
        "    output = model(embedding)\n",
        "    label = 'Subjective' if output > 0.5 else 'Objective'\n",
        "    return label\n",
        "\n",
        "gr.Interface(fn=classify_sentence, inputs=\"text\", outputs=\"text\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "iXmfEDUY2hs2",
        "outputId": "50356765-6f9d-4bcf-ae09-ac84622fc051"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://87e008d7762471abdc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://87e008d7762471abdc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}